<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title></title>
  <meta name="description" content="This document contains the PhD thesis of Filippo Chiarello.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This document contains the PhD thesis of Filippo Chiarello." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="" />
  
  <meta name="twitter:description" content="This document contains the PhD thesis of Filippo Chiarello." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="defining-industry-4-0-professional-archetypes.html">
<link rel="next" href="future-developments.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Mining Technical Knowledge</a></li>

<li class="divider"></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="scope-of-the-thesis.html"><a href="scope-of-the-thesis.html"><i class="fa fa-check"></i><b>1</b> Scope of the Thesis</a><ul>
<li class="chapter" data-level="1.1" data-path="scope-of-the-thesis.html"><a href="scope-of-the-thesis.html#sources-of-information"><i class="fa fa-check"></i><b>1.1</b> Sources of Information</a></li>
<li class="chapter" data-level="1.2" data-path="scope-of-the-thesis.html"><a href="scope-of-the-thesis.html#methods-and-focus-of-the-analysis"><i class="fa fa-check"></i><b>1.2</b> Methods and Focus of the Analysis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="approach.html"><a href="approach.html"><i class="fa fa-check"></i><b>2</b> Approach</a><ul>
<li class="chapter" data-level="2.1" data-path="approach.html"><a href="approach.html#introdesres"><i class="fa fa-check"></i><b>2.1</b> Design Science Paradigm</a></li>
<li class="chapter" data-level="2.2" data-path="approach.html"><a href="approach.html#data-science-workflow"><i class="fa fa-check"></i><b>2.2</b> Data Science Workflow</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="structure-and-rationale.html"><a href="structure-and-rationale.html"><i class="fa fa-check"></i>Structure and Rationale</a></li>
<li class="part"><span><b>II State of the Art</b></span></li>
<li class="chapter" data-level="3" data-path="sotatools.html"><a href="sotatools.html"><i class="fa fa-check"></i><b>3</b> Phases, Tasks, and Techniques</a><ul>
<li class="chapter" data-level="3.1" data-path="sotatools.html"><a href="sotatools.html#sotatoolsprogram"><i class="fa fa-check"></i><b>3.1</b> Program</a></li>
<li class="chapter" data-level="3.2" data-path="sotatools.html"><a href="sotatools.html#sotatoolsimport"><i class="fa fa-check"></i><b>3.2</b> Import</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sotatools.html"><a href="sotatools.html#sotatoolsimportretrieval"><i class="fa fa-check"></i><b>3.2.1</b> Document Retrieval</a></li>
<li class="chapter" data-level="3.2.2" data-path="sotatools.html"><a href="sotatools.html#sotatoolsimportformat"><i class="fa fa-check"></i><b>3.2.2</b> Documents Format</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sotatools.html"><a href="sotatools.html#sotatoolstidy"><i class="fa fa-check"></i><b>3.3</b> Tidy</a></li>
<li class="chapter" data-level="3.4" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransform"><i class="fa fa-check"></i><b>3.4</b> Transform</a><ul>
<li class="chapter" data-level="3.4.1" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformsentencesplit"><i class="fa fa-check"></i><b>3.4.1</b> Sentence Splitting</a></li>
<li class="chapter" data-level="3.4.2" data-path="sotatools.html"><a href="sotatools.html#tokenization"><i class="fa fa-check"></i><b>3.4.2</b> Tokenization</a></li>
<li class="chapter" data-level="3.4.3" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformstemming"><i class="fa fa-check"></i><b>3.4.3</b> Stemming</a></li>
<li class="chapter" data-level="3.4.4" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformlemmatisation"><i class="fa fa-check"></i><b>3.4.4</b> Lemmatisation</a></li>
<li class="chapter" data-level="3.4.5" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformwi"><i class="fa fa-check"></i><b>3.4.5</b> Words importance metrics</a></li>
<li class="chapter" data-level="3.4.6" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformpos"><i class="fa fa-check"></i><b>3.4.6</b> Part-of-Speech Tagging</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodel"><i class="fa fa-check"></i><b>3.5</b> Model</a><ul>
<li class="chapter" data-level="3.5.1" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformngrams"><i class="fa fa-check"></i><b>3.5.1</b> N-Grams</a></li>
<li class="chapter" data-level="3.5.2" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodeldocclass"><i class="fa fa-check"></i><b>3.5.2</b> Document Classification</a></li>
<li class="chapter" data-level="3.5.3" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodelsentanal"><i class="fa fa-check"></i><b>3.5.3</b> Sentiment Analysis</a></li>
<li class="chapter" data-level="3.5.4" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodelnetanal"><i class="fa fa-check"></i><b>3.5.4</b> Text Clustering</a></li>
<li class="chapter" data-level="3.5.5" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodelner"><i class="fa fa-check"></i><b>3.5.5</b> Named Entity Recognition</a></li>
<li class="chapter" data-level="3.5.6" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodeltopicmodel"><i class="fa fa-check"></i><b>3.5.6</b> Topic Modelling</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="sotatools.html"><a href="sotatools.html#sotatoolsvisualize"><i class="fa fa-check"></i><b>3.6</b> Visualize</a><ul>
<li class="chapter" data-level="3.6.1" data-path="sotatools.html"><a href="sotatools.html#the-grammar-of-graphics"><i class="fa fa-check"></i><b>3.6.1</b> The Grammar of Graphics</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="sotatools.html"><a href="sotatools.html#sotatoolscomunicate"><i class="fa fa-check"></i><b>3.7</b> Comunicate</a></li>
<li class="chapter" data-level="3.8" data-path="sotatools.html"><a href="sotatools.html#sotadocumentsunderstand"><i class="fa fa-check"></i><b>3.8</b> Understand</a><ul>
<li class="chapter" data-level="3.8.1" data-path="sotatools.html"><a href="sotatools.html#sotadocumentsunderstandbyas"><i class="fa fa-check"></i><b>3.8.1</b> The problem of biases</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sotadocuments.html"><a href="sotadocuments.html"><i class="fa fa-check"></i><b>4</b> Documents</a><ul>
<li class="chapter" data-level="4.1" data-path="sotadocuments.html"><a href="sotadocuments.html#sotadocumentspatents"><i class="fa fa-check"></i><b>4.1</b> Patents</a><ul>
<li class="chapter" data-level="4.1.1" data-path="sotadocuments.html"><a href="sotadocuments.html#metadata-approaches"><i class="fa fa-check"></i><b>4.1.1</b> Metadata Approaches</a></li>
<li class="chapter" data-level="4.1.2" data-path="sotadocuments.html"><a href="sotadocuments.html#keywords-approaches"><i class="fa fa-check"></i><b>4.1.2</b> Keywords Approaches</a></li>
<li class="chapter" data-level="4.1.3" data-path="sotadocuments.html"><a href="sotadocuments.html#natural-language-processing-approaches"><i class="fa fa-check"></i><b>4.1.3</b> Natural Language Processing approaches</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sotadocuments.html"><a href="sotadocuments.html#sotadocumentspapers"><i class="fa fa-check"></i><b>4.2</b> Papers</a></li>
<li class="chapter" data-level="4.3" data-path="sotadocuments.html"><a href="sotadocuments.html#sotadocumentswiki"><i class="fa fa-check"></i><b>4.3</b> Wikipedia</a></li>
<li class="chapter" data-level="4.4" data-path="sotadocuments.html"><a href="sotadocuments.html#sotadocumentstwitter"><i class="fa fa-check"></i><b>4.4</b> Social Media</a><ul>
<li class="chapter" data-level="4.4.1" data-path="sotadocuments.html"><a href="sotadocuments.html#economics"><i class="fa fa-check"></i><b>4.4.1</b> Economics</a></li>
<li class="chapter" data-level="4.4.2" data-path="sotadocuments.html"><a href="sotadocuments.html#marketing"><i class="fa fa-check"></i><b>4.4.2</b> Marketing</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Methods and Results</b></span></li>
<li class="chapter" data-level="5" data-path="patents.html"><a href="patents.html"><i class="fa fa-check"></i><b>5</b> Patents</a><ul>
<li class="chapter" data-level="5.1" data-path="patents.html"><a href="patents.html#usersresults"><i class="fa fa-check"></i><b>5.1</b> Users</a><ul>
<li class="chapter" data-level="5.1.1" data-path="patents.html"><a href="patents.html#method"><i class="fa fa-check"></i><b>5.1.1</b> Method</a></li>
<li class="chapter" data-level="5.1.2" data-path="patents.html"><a href="patents.html#results"><i class="fa fa-check"></i><b>5.1.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="patents.html"><a href="patents.html#advdrwresults"><i class="fa fa-check"></i><b>5.2</b> Advantages and Drawbacks</a><ul>
<li class="chapter" data-level="5.2.1" data-path="patents.html"><a href="patents.html#methodology"><i class="fa fa-check"></i><b>5.2.1</b> Methodology</a></li>
<li class="chapter" data-level="5.2.2" data-path="patents.html"><a href="patents.html#results-1"><i class="fa fa-check"></i><b>5.2.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="patents.html"><a href="patents.html#trademakrs"><i class="fa fa-check"></i><b>5.3</b> Trademakrs</a><ul>
<li class="chapter" data-level="5.3.1" data-path="patents.html"><a href="patents.html#methodology-1"><i class="fa fa-check"></i><b>5.3.1</b> Methodology</a></li>
<li class="chapter" data-level="5.3.2" data-path="patents.html"><a href="patents.html#results-2"><i class="fa fa-check"></i><b>5.3.2</b> Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="papers.html"><a href="papers.html"><i class="fa fa-check"></i><b>6</b> Papers</a><ul>
<li class="chapter" data-level="6.1" data-path="papers.html"><a href="papers.html#smtextdrivenbottomup"><i class="fa fa-check"></i><b>6.1</b> Sustainable Manufacturing: an Analysis of the 6R Framework</a><ul>
<li class="chapter" data-level="6.1.1" data-path="papers.html"><a href="papers.html#methodology-2"><i class="fa fa-check"></i><b>6.1.1</b> Methodology</a></li>
<li class="chapter" data-level="6.1.2" data-path="papers.html"><a href="papers.html#results-3"><i class="fa fa-check"></i><b>6.1.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="papers.html"><a href="papers.html#sustainable-manufacturing-an-extended-mapping"><i class="fa fa-check"></i><b>6.2</b> Sustainable Manufacturing: An Extended Mapping</a><ul>
<li class="chapter" data-level="6.2.1" data-path="papers.html"><a href="papers.html#methodology-3"><i class="fa fa-check"></i><b>6.2.1</b> Methodology</a></li>
<li class="chapter" data-level="6.2.2" data-path="papers.html"><a href="papers.html#results-4"><i class="fa fa-check"></i><b>6.2.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="papers.html"><a href="papers.html#blockchainanalysis"><i class="fa fa-check"></i><b>6.3</b> Blockchain</a><ul>
<li class="chapter" data-level="6.3.1" data-path="papers.html"><a href="papers.html#methodology-4"><i class="fa fa-check"></i><b>6.3.1</b> Methodology</a></li>
<li class="chapter" data-level="6.3.2" data-path="papers.html"><a href="papers.html#results-5"><i class="fa fa-check"></i><b>6.3.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="papers.html"><a href="papers.html#precisionagri"><i class="fa fa-check"></i><b>6.4</b> Precision Agriculture</a><ul>
<li class="chapter" data-level="6.4.1" data-path="papers.html"><a href="papers.html#methodology-5"><i class="fa fa-check"></i><b>6.4.1</b> Methodology</a></li>
<li class="chapter" data-level="6.4.2" data-path="papers.html"><a href="papers.html#results-6"><i class="fa fa-check"></i><b>6.4.2</b> Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="wikipedia.html"><a href="wikipedia.html"><i class="fa fa-check"></i><b>7</b> Wikipedia</a><ul>
<li class="chapter" data-level="7.1" data-path="wikipedia.html"><a href="wikipedia.html#technimetrochap"><i class="fa fa-check"></i><b>7.1</b> Industry 4.0: Extracting and Mapping Technologies</a><ul>
<li class="chapter" data-level="7.1.1" data-path="wikipedia.html"><a href="wikipedia.html#methodology-6"><i class="fa fa-check"></i><b>7.1.1</b> Methodology</a></li>
<li class="chapter" data-level="7.1.2" data-path="wikipedia.html"><a href="wikipedia.html#results-7"><i class="fa fa-check"></i><b>7.1.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="wikipedia.html"><a href="wikipedia.html#industry-4.0-a-comparison-with-industrie-4.0"><i class="fa fa-check"></i><b>7.2</b> Industry 4.0: a Comparison with Industrie 4.0</a><ul>
<li class="chapter" data-level="7.2.1" data-path="wikipedia.html"><a href="wikipedia.html#methodology-7"><i class="fa fa-check"></i><b>7.2.1</b> Methodology</a></li>
<li class="chapter" data-level="7.2.2" data-path="wikipedia.html"><a href="wikipedia.html#results-8"><i class="fa fa-check"></i><b>7.2.2</b> Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="social-media.html"><a href="social-media.html"><i class="fa fa-check"></i><b>8</b> Social Media</a><ul>
<li class="chapter" data-level="8.1" data-path="social-media.html"><a href="social-media.html#techsentanal"><i class="fa fa-check"></i><b>8.1</b> Technical Sentiment Analysis</a><ul>
<li class="chapter" data-level="8.1.1" data-path="social-media.html"><a href="social-media.html#methodology-8"><i class="fa fa-check"></i><b>8.1.1</b> Methodology</a></li>
<li class="chapter" data-level="8.1.2" data-path="social-media.html"><a href="social-media.html#results-9"><i class="fa fa-check"></i><b>8.1.2</b> Results</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Applications of the Results</b></span></li>
<li class="chapter" data-level="9" data-path="explpatentnovel.html"><a href="explpatentnovel.html"><i class="fa fa-check"></i><b>9</b> A Novel Rapresentation of Patents in Terms of Adantages and Drawbacks</a><ul>
<li class="chapter" data-level="9.1" data-path="explpatentnovel.html"><a href="explpatentnovel.html#towards-formal-definitions-of-advantages-and-drawbacks"><i class="fa fa-check"></i><b>9.1</b> Towards Formal Definitions of Advantages and Drawbacks</a></li>
<li class="chapter" data-level="9.2" data-path="explpatentnovel.html"><a href="explpatentnovel.html#methodology-9"><i class="fa fa-check"></i><b>9.2</b> Methodology</a><ul>
<li class="chapter" data-level="9.2.1" data-path="explpatentnovel.html"><a href="explpatentnovel.html#advantages-and-drawbacks-extraction"><i class="fa fa-check"></i><b>9.2.1</b> Advantages and drawbacks extraction</a></li>
<li class="chapter" data-level="9.2.2" data-path="explpatentnovel.html"><a href="explpatentnovel.html#advantages-and-drawbacks-adio-classification"><i class="fa fa-check"></i><b>9.2.2</b> Advantages and Drawbacks ADIO classification</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="explpatentnovel.html"><a href="explpatentnovel.html#results-10"><i class="fa fa-check"></i><b>9.3</b> Results</a><ul>
<li class="chapter" data-level="9.3.1" data-path="explpatentnovel.html"><a href="explpatentnovel.html#patent-set"><i class="fa fa-check"></i><b>9.3.1</b> Patent set</a></li>
<li class="chapter" data-level="9.3.2" data-path="explpatentnovel.html"><a href="explpatentnovel.html#extraction-of-advantages-and-drawbacks"><i class="fa fa-check"></i><b>9.3.2</b> Extraction of Advantages and Drawbacks</a></li>
<li class="chapter" data-level="9.3.3" data-path="explpatentnovel.html"><a href="explpatentnovel.html#a-d-i-o-representation"><i class="fa fa-check"></i><b>9.3.3</b> A-D-I-O Representation</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="explpatentnovel.html"><a href="explpatentnovel.html#discussion"><i class="fa fa-check"></i><b>9.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="enriched-dictionaries-for-innovation.html"><a href="enriched-dictionaries-for-innovation.html"><i class="fa fa-check"></i><b>10</b> Enriched dictionaries for Innovation</a><ul>
<li class="chapter" data-level="10.1" data-path="enriched-dictionaries-for-innovation.html"><a href="enriched-dictionaries-for-innovation.html#an-overview-of-dictionaries-for-technology-intelligence"><i class="fa fa-check"></i><b>10.1</b> An overview of dictionaries for technology intelligence</a><ul>
<li class="chapter" data-level="10.1.1" data-path="enriched-dictionaries-for-innovation.html"><a href="enriched-dictionaries-for-innovation.html#publicly-available-dictionaries"><i class="fa fa-check"></i><b>10.1.1</b> Publicly available dictionaries</a></li>
<li class="chapter" data-level="10.1.2" data-path="enriched-dictionaries-for-innovation.html"><a href="enriched-dictionaries-for-innovation.html#research-based-dictionaries"><i class="fa fa-check"></i><b>10.1.2</b> Research-based dictionaries</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="enriched-dictionaries-for-innovation.html"><a href="enriched-dictionaries-for-innovation.html#the-value-added-of-enriched-dictionaries"><i class="fa fa-check"></i><b>10.2</b> The value added of enriched dictionaries</a></li>
<li class="chapter" data-level="10.3" data-path="enriched-dictionaries-for-innovation.html"><a href="enriched-dictionaries-for-innovation.html#methodology-10"><i class="fa fa-check"></i><b>10.3</b> Methodology</a></li>
<li class="chapter" data-level="10.4" data-path="enriched-dictionaries-for-innovation.html"><a href="enriched-dictionaries-for-innovation.html#results-11"><i class="fa fa-check"></i><b>10.4</b> Results</a></li>
<li class="chapter" data-level="10.5" data-path="enriched-dictionaries-for-innovation.html"><a href="enriched-dictionaries-for-innovation.html#discussions"><i class="fa fa-check"></i><b>10.5</b> Discussions</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="impactresuser.html"><a href="impactresuser.html"><i class="fa fa-check"></i><b>11</b> Impact of Research from the Perspective of Users</a><ul>
<li class="chapter" data-level="11.1" data-path="impactresuser.html"><a href="impactresuser.html#methodological-challenges"><i class="fa fa-check"></i><b>11.1</b> Methodological challenges</a><ul>
<li class="chapter" data-level="11.1.1" data-path="impactresuser.html"><a href="impactresuser.html#variability-in-the-identification-of-outcomes-and-users"><i class="fa fa-check"></i><b>11.1.1</b> Variability in the identification of outcomes and users</a></li>
<li class="chapter" data-level="11.1.2" data-path="impactresuser.html"><a href="impactresuser.html#sources-of-information-1"><i class="fa fa-check"></i><b>11.1.2</b> Sources of information</a></li>
<li class="chapter" data-level="11.1.3" data-path="impactresuser.html"><a href="impactresuser.html#text-based-impact-assessment"><i class="fa fa-check"></i><b>11.1.3</b> Text-based impact assessment</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="impactresuser.html"><a href="impactresuser.html#methodology-11"><i class="fa fa-check"></i><b>11.2</b> Methodology</a><ul>
<li class="chapter" data-level="11.2.1" data-path="impactresuser.html"><a href="impactresuser.html#operationalizing-user-groups-using-natural-language-processing-techniques"><i class="fa fa-check"></i><b>11.2.1</b> Operationalizing user groups using Natural Language Processing techniques</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="impactresuser.html"><a href="impactresuser.html#from-text-extraction-to-indicators"><i class="fa fa-check"></i><b>11.3</b> From text extraction to indicators</a><ul>
<li class="chapter" data-level="" data-path="impactresuser.html"><a href="impactresuser.html#frequency"><i class="fa fa-check"></i>Frequency</a></li>
<li class="chapter" data-level="" data-path="impactresuser.html"><a href="impactresuser.html#diversity"><i class="fa fa-check"></i>Diversity</a></li>
<li class="chapter" data-level="" data-path="impactresuser.html"><a href="impactresuser.html#specificity"><i class="fa fa-check"></i>Specificity</a></li>
<li class="chapter" data-level="11.3.1" data-path="impactresuser.html"><a href="impactresuser.html#the-meaning-of-frequency-diversity-and-specificity-indicators-for-the-analysis-of-research-impact"><i class="fa fa-check"></i><b>11.3.1</b> The meaning of Frequency, Diversity and Specificity indicators for the analysis of research impact</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="impactresuser.html"><a href="impactresuser.html#data"><i class="fa fa-check"></i><b>11.4</b> Data</a><ul>
<li class="chapter" data-level="11.4.1" data-path="impactresuser.html"><a href="impactresuser.html#description-of-the-corpus"><i class="fa fa-check"></i><b>11.4.1</b> Description of the corpus</a></li>
<li class="chapter" data-level="11.4.2" data-path="impactresuser.html"><a href="impactresuser.html#preliminary-analysis-of-the-corpus"><i class="fa fa-check"></i><b>11.4.2</b> Preliminary analysis of the corpus</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="impactresuser.html"><a href="impactresuser.html#results-12"><i class="fa fa-check"></i><b>11.5</b> Results</a><ul>
<li class="chapter" data-level="11.5.1" data-path="impactresuser.html"><a href="impactresuser.html#descriptive-analysis"><i class="fa fa-check"></i><b>11.5.1</b> Descriptive analysis</a></li>
<li class="chapter" data-level="11.5.2" data-path="impactresuser.html"><a href="impactresuser.html#findings-by-subject-area"><i class="fa fa-check"></i><b>11.5.2</b> Findings by subject area</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="impactresuser.html"><a href="impactresuser.html#discussion-1"><i class="fa fa-check"></i><b>11.6</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="defining-industry-4-0-professional-archetypes.html"><a href="defining-industry-4-0-professional-archetypes.html"><i class="fa fa-check"></i><b>12</b> Defining Industry 4.0 Professional Archetypes</a><ul>
<li class="chapter" data-level="12.1" data-path="defining-industry-4-0-professional-archetypes.html"><a href="defining-industry-4-0-professional-archetypes.html#digital-competences-development"><i class="fa fa-check"></i><b>12.1</b> Digital Competences Development</a></li>
<li class="chapter" data-level="12.2" data-path="defining-industry-4-0-professional-archetypes.html"><a href="defining-industry-4-0-professional-archetypes.html#methodology-12"><i class="fa fa-check"></i><b>12.2</b> Methodology</a></li>
<li class="chapter" data-level="12.3" data-path="defining-industry-4-0-professional-archetypes.html"><a href="defining-industry-4-0-professional-archetypes.html#the-archetypes"><i class="fa fa-check"></i><b>12.3</b> The Archetypes</a></li>
<li class="chapter" data-level="12.4" data-path="defining-industry-4-0-professional-archetypes.html"><a href="defining-industry-4-0-professional-archetypes.html#discussions-1"><i class="fa fa-check"></i><b>12.4</b> Discussions</a></li>
</ul></li>
<li class="part"><span><b>V Conclusions</b></span></li>
<li class="chapter" data-level="13" data-path="sotadocumentsunderstandlexicons.html"><a href="sotadocumentsunderstandlexicons.html"><i class="fa fa-check"></i><b>13</b> Lexicons Design for Mining Technical Knowledge</a><ul>
<li class="chapter" data-level="13.1" data-path="sotadocumentsunderstandlexicons.html"><a href="sotadocumentsunderstandlexicons.html#the-knowledge-bases-and-technical-lexicons"><i class="fa fa-check"></i><b>13.1</b> The Knowledge Bases and Technical Lexicons</a></li>
<li class="chapter" data-level="13.2" data-path="sotadocumentsunderstandlexicons.html"><a href="sotadocumentsunderstandlexicons.html#the-history-of-lexicons-design"><i class="fa fa-check"></i><b>13.2</b> The history of Lexicons Design</a></li>
<li class="chapter" data-level="13.3" data-path="sotadocumentsunderstandlexicons.html"><a href="sotadocumentsunderstandlexicons.html#a-map-for-lexicons-design"><i class="fa fa-check"></i><b>13.3</b> A Map for Lexicons Design</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="future-developments.html"><a href="future-developments.html"><i class="fa fa-check"></i><b>14</b> Future Developments</a></li>
<li class="chapter" data-level="" data-path="glossary.html"><a href="glossary.html"><i class="fa fa-check"></i>Glossary</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sotadocumentsunderstandlexicons" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> Lexicons Design for Mining Technical Knowledge</h1>
<p>In this work as been shown that text mining techniques are being adopted in many different fields to face the problem of extracting meaningful information hidden in unstructured data. Hybrid processes (human-machine) of knowledge extraction are usually the best solution for companies to achieve great results and to ensure the conformity of the output of the knowledge extraction process. Anyway, state-of-art literature on Natural Language Processing (NLP) lacks in process management studies. In particular, researchers have not yet studied the best way to integrate NLP outputs with human activities. To our best knowledge, the present thesis is a first step in the desired direction. Such a process and the design of new methods for human-machine (or better engineers machine) interaction , started with the present thesis, bring some valuable contribution to the literature:</p>
<ul>
<li><p>Minimize the introduction of errors and biases made by human intervention;</p></li>
<li><p>Maximize the human effort only on value added tasks such as knowledge validation and consolidation;</p></li>
<li><p>Decrease the overall time of the process.</p></li>
</ul>
<p>From this thesis emerges the fact that <em>Information Extraction from texts for developing technical dictionaries (a Knowledge Base), is a effective approach to follow in order to increase the knowledge base of a specific field.</em> Many of the designs presented in this thesis uses this approach.</p>
<p>In section <a href="patents.html#usersresults">5.1</a> a dictionary of <em>users of inventions</em> has been developed, containing more than 76.000 entries, and this dictionary has been used to analyze projects texts <a href="impactresuser.html#impactresuser">11</a>. In section <a href="patents.html#advdrwresults">5.2</a> a dictionary of <em>advantages and drawbacks</em> has been extracted from patents using twitter to validate its content. The dictionary contains a total of 6.568 advantages and the 14.809 drawbacks and has been used to classify problems of different technologies in patents <a href="explpatentnovel.html#explpatentnovel">9</a> and papers <a href="papers.html#blockchainanalysis">6.3</a>. This dictionary has also been used to design a novel technical sentiment analysis, which has been used to analyze the sentiment about two innovative products in section <a href="social-media.html#techsentanal">8.1</a>.</p>
<p>Sections <a href="papers.html#smtextdrivenbottomup">6.1</a>, <a href="papers.html#precisionagri">6.4</a> and <a href="wikipedia.html#technimetrochap">7.1</a> developed dictionaries for respectively sustainable manufacturing, precision agriculture and industry 4.0 with the aim of giving a clear picture to both academics and practitioners about the state of the of art of technologies in these fields. In particular in section <a href="wikipedia.html#technimetrochap">7.1</a> the dictionary is an enriched dictionary: the enriched dictionary can be defined as a set of enabling technologies for industry 4.0, associated to their definitions and to the linkages between them.</p>
<p>In this final chapter of the thesis we give a descriptive-science view of the results. We thus present a general method that has proven to be effective in the major part of the designs of the present thesis: <strong>lexicons design</strong>.</p>
<div id="the-knowledge-bases-and-technical-lexicons" class="section level2">
<h2><span class="header-section-number">13.1</span> The Knowledge Bases and Technical Lexicons</h2>
<p>A Knowledge Base is an organized repository of knowledge - in a computer system or an organization - consisting of concepts, data, objectives, requirements, rules, or specifications. Technical Lexicons (or Dictionaries) are lists of keywords and expressions linked to a specific topic and they are used to extract information through the research of these keywords in raw texts. All the methods that use these lists of keywords are named Dictionary-based Approaches.</p>
<p>For using these approaches, the first thing to do is the construction of these dictionaries. For some applications - i.e. biomedical fields - there are already existing dictionaries that can be used for text mining; in other applications, these dictionaries need to be constructed. The development of dictionary is a task still too human-dependent: in fact, for building these lists, domain experts must select keywords from texts and clear them from words that are too general for that domain; this process must be repeated iteratively until a satisfactory result is achieved, in relation with the purpose. These tasks rely too much on the intervention of experts and the subsequent analysis are greatly influenced from their choices and opinions. Experts intervention is also too time consuming and expensive.</p>
<p>Another way to increase the Knowledge Base is through the Named-Entity Recognition Techniques. Named-entity recognition (NER) - also known as entity identification, entity chunking and entity extraction- is a subtask of Information Extraction that seeks to locate and classify named entities in text into pre-defined categories as names, locations, quantity, and others. These techniques usually take an unlabeled text and produce an annotation on it, extracting the entities of some predefined categories.</p>
</div>
<div id="the-history-of-lexicons-design" class="section level2">
<h2><span class="header-section-number">13.2</span> The history of Lexicons Design</h2>
<p>In order to map the main techniques used for Lexicons Design, 23 papers have been analysed and mapped.</p>
<p>In 2014, Song et al <span class="citation">(Song, Yu, and Han <a href="#ref-song2015developing">2015</a>)</span> developed a hybrid dictionary-based bio-entity recognition technique based on the expansion of the bio-entity dictionary by combining different data sources and using the approximate string matching technique and the shortest path edit distance algorithm. The technique also adopts text mining techniques in the merging stage of similar entities such as Part of Speech (POS) expansion, stemming, and the exploitation of the contextual cues to further improve the performance.</p>
<p>In 2015, Yang and Garibaldi <span class="citation">(Yang and Garibaldi <a href="#ref-yang2015hybrid">2015</a>)</span> described a hybrid information extraction system to automatically identify risk factors for heart disease in medical records. Their approaches rely on several natural language processing (NLP) techniques such as machine learning, rule-based methods, and dictionary-based keyword spotting to cope with complicated clinical contexts inherent in a wide variety of risk factors.</p>
<p>In 2016, Arif-Uz-Zaman et al <span class="citation">(Arif-Uz-Zaman et al. <a href="#ref-arif2017extracting">2017</a>)</span> used text mining for industrial application, proposing a text mining approach to extract accurate failure time data from WOs (work orders which detail maintenance activities on the asset) and DD (downtime data which details when the asset was taken offline). Texts are pre-processed and the WOs are manually labeled as potential failure or non-failure. Then a keyword dictionary is developed from the WOs. Labels and the keyword dictionary are used to classify each DDs downtime event as a failure or non-failure.</p>
<p>Kim and Joung <span class="citation">(Joung and Kim <a href="#ref-joung2017monitoring">2017</a>)</span> proposed a technical keyword-based analysis of patents to monitor emerging technologies, and used a keyword-based model in contents-based patent analysis. Technical keywords are extracted using a commercial NLP software package, then selected using a TF-IDF function. After that, a technical keyword-context matrix is constructed. The relatedness between pairs of keywords is then identified , and patent documents are clustered by using a hierarchical clustering algorithm based on patent document vectors. As a result, emerging technologies can be monitored by identifying clusters composed of technical keywords.</p>
<p>In 2017, Rezaeian et al <span class="citation">(Rezaeian, Montazeri, and Loonen <a href="#ref-rezaeian2017science">2017</a>)</span> described a three-step methodological framework for science foresight on the basis of published research papers, consisting of life-cycle analysis, text mining and knowledge gap identification by means of automated clustering. Moro et al <span class="citation">Amado et al. (<a href="#ref-amado2018research">2018</a>)</span>] presented a research literature analysis based on a text mining semi-automated approach with the goal of identifying the main trends in Big Data in Marketing. The study includes dictionaries built by keywords extraction, experts’ judgment and usage of sources as Bloomberg and Google Finance. Text mining results in a matrix structure used as input to the LDA algorithm of Topic Modeling, that groups articles in logical topics characterized by key relevant terms.</p>
<p>Baechle et al <span class="citation">(Baechle, Agarwal, and Zhu <a href="#ref-baechle2017big">2017</a>)</span> presented a method to examine several de-identified clinical notes and discover associations between Chronic Obstructive Pulmonary Disease and medical terms. A natural language processing system is leveraged to annotate and structure clinical notes. In order to analyse the performance of retrieved results, dictionaries of terms for diseases, medications, and symptoms have been created using clinical domain knowledge.</p>
<p>Fan et al <span class="citation">(Chen et al. <a href="#ref-chen2017revealing">2017</a>)</span> used a Bio-Dynamic Topic Modeling (DTM) for revealing topics and their evolution in biomedical literature. The system of Bio-DTM mainly includes four components, documents pre-processing, bio-dictionary construction with the use of medical sources, dynamic topic models, topics analysis and visualization.</p>
<p>Finally, Karystianis et al <span class="citation">(Karystianis et al. <a href="#ref-karystianis2017evaluation">2017</a>)</span> proposed a knowledge-driven, rule-based approach to identify targeted information from abstracts of epidemiological studies. Their methodology involved the design and implementation of generic rules that enable the recognition of mentions of elements in the right context in epidemiological study abstracts, using dictionaries of targeted elements. Since the dictionaries are concept specific for the outcomes and exposures, they are manually crafted because of their quickly development.</p>
<p>Regarding the NER techniques, in 2008 Sasaki et al <span class="citation">(Sasaki et al. <a href="#ref-sasaki2008make">2008</a>)</span> suggested a novel way to improve the NER performance by adding Named Entities (NEs) to an NE dictionary without retraining. In their approach, known NEs are identified in parallel with Part-of-Speech (POS) tagging based on a general word dictionary and an NE dictionary. Then, statistical NER is trained on the POS/PROTEIN tagger outputs with correct NE labels attached. In particular, they use CRF models to predict the label of entities.</p>
<p>In 2009, Yang et al <span class="citation">(Xu, Yang, and Li <a href="#ref-xu2009named">2009</a>)</span> conducted a Named Entity Mining (NEM) by using click-through data collected at a web search engine, employing the Weak Supervised Latent Dirichlet Allocation (WS-LDA) topic model technique that generates the click-through data, and learning the topic model by weak supervision from humans. The method then applies the acquired patterns into the click-through data to mine new named entities. It outputs the top ranked named entities for each class, as well as patterns of each class.</p>
<p>In 2014, Mahalakshmi et al <span class="citation">(Mahalakshmi, Vijayan, and Antony <a href="#ref-mahalakshmi2018named">2018</a>)</span> described a way for automating the test process from the early stages of requirement elicitation in the development of software. They proposed a semi- supervised technique to generate test cases by identifying named entities in the given set of use cases. The Named Entity Recognizer model used is Maximum Entropy Model (MEM), that is trained by a set of features extracted from the use cases. The Named Entities found are saved in the NE dictionary in their domain which can be referred in future for other set of use cases.</p>
<p>Also in 2014, Konkol et al <span class="citation">(Konkol, Brychcín, and Konopík <a href="#ref-konkol2015latent">2015</a>)</span> proposed a new feature for NER based on latent semantic and explored the effect of unsupervised morphological information on these methods and on the NER system in general. Rather than using gazetteers -lists of named entities of the same type- made by human experts as semantic features, they use words and phrases clusters and use word similarity based on semantic spaces to create these clusters. These clusters are then used to represent the local semantic information. They also used topic models - LDA in particular- and enrich features by a language-independent unsupervised stemming. In 2015, Chen et al <span class="citation">(Liu et al. <a href="#ref-liu2015effects">2015</a>)</span> investigated the effect of semantic features based on word embeddings on DNR and compare them with semantic features based on three drug dictionaries. They propose a Conditional Random Fields-based system for Drug Name Recognition. Rather than using classical semantic features based on drug dictionaries manually constructed by experts, they use word embeddings. The skip-gram model, an unsupervised algorithm, is used to induce word embeddings on unlabelled biomedical texts.</p>
<p>Song et al <span class="citation">(Song et al. <a href="#ref-song2015pkde4j">2015</a>)</span> presented a comprehensive text-mining system that integrates dictionary-based entity extraction and rule-based relation extraction in a highly flexible and extensible framework. They developed an extensible rule engine based on dependency parsing for relation extraction in order to develop a predictive model that was effective in general. A set of rules is applied to identify whether a relation exists in a sentence and to determine its relation type.</p>
<p>In 2017, Natarajan et al <span class="citation">(Murugesan et al. <a href="#ref-murugesan2017bcc">2017</a>)</span> described an hybrid named entity tagging composed of three modules: the first is for text processing, which includes basic NLP pre-processing, feature extraction, and feature selection; the second is for training and model building with bidirectional Conditional Random Fields to parse the text in both directions (forward and backward); the final module is for post-processing, which includes surrounding text features, parenthesis mismatching, and two-tier abbreviation algorithm.</p>
<p>Rinaldi et al <span class="citation">(Basaldella et al. <a href="#ref-basaldella2017entity">2017</a>)</span> showed an approach that uses a two-stage pipeline, combining a dictionary- based entity recognizer with a machine-learning classifier. First, the dictionary stage annotates the terms that appear in selected domain ontologies. Subsequently, the machine learning stage uses this information as a feature for two machine learning algorithms, Conditional Random Fields and Neural Networks, to select the relevant entities only.</p>
<p>Unanue et al <span class="citation">(Unanue, Borzeshi, and Piccardi <a href="#ref-unanue2017recurrent">2017</a>)</span> proposed two deep learning methods to create a highly accurate Drug Name Recognition and Clinical Concept Extraction system that avoids conventional, time-consuming feature engineering and to develop more specialized word embeddings by using health domain datasets. Two deep learning methods are the Bidirectional LSTM and the Bidirectional LSTM-CRF. A CRF model is set as the baseline to compare the deep learning systems to a traditional machine learning approach and the same features are used for all the models.</p>
<p>To solve the issue of biomedical names ambiguity in knowledge extraction, Huang et al <span class="citation">(Huang et al. <a href="#ref-huang2018novel">2018</a>)</span> presented a novel approach to disambiguating gene/protein names by using context graphs. In order to obtain the domain knowledge, a context graphs is built by examining the co- occurrence word relationship in a set of abstract of document, rather than by relying on expensive experts’ judgements. They propose a method that integrates the word frequency, dispersion degree and concentration degree. Finally, entity resolution is performed by applying a Support Vector Machine.</p>
<p>Venkatasubramanian et al <span class="citation">(Remolona et al. <a href="#ref-remolona2017hybrid">2017</a>)</span> developed an approach that integrates a variety of machine learning and natural language processing methods to extract information from journal articles and store them semantically in an ontology. In this work, identification of key terms - such as chemicals, drugs, processes, anatomical entities, etc. - from abstracts, and the classification of these terms into 25 classes are presented. They tested two methods - a multi-class classifier (SVM) and a multi-label classifier (HOMER)- on an annotated data set for the pharmaceutical industry.</p>
<p>In 2018, Gupta et al <span class="citation">(Gupta, Banerjee, and Rubin <a href="#ref-gupta2018automatic">2018</a>)</span> propose a hybrid approach that combines dependency-based parse tree with distributed semantics for generating structured information frames about particular findings from the free-text mammography reports. To do this, they follow three steps: Extraction of relation through tokenization, sentence splitting, POS tagging, Dependency Parsing and Relation extraction; Clustering of relations through Word2Vec and k-means method; Association of relations with their arguments and construction of information frames. Chen et al <span class="citation">(Wang et al. <a href="#ref-wang2018information">2018</a>)</span> present a workflow for information extraction and knowledge discovery from textual geoscience data. They set up a hybrid corpus combining the generic and geology terms from geology dictionaries to train word segmentation rules of the Conditional Random Fields model. Then, they parsed documents and get a corpus constituted of content-words. Finally, they use a statistical method to analyze the semantic links between content words, and they use a knowledge graph to visualize these links and to map a clear overview of key information in an unstructured document. Also in 2018, An et al <span class="citation">(An et al. <a href="#ref-an2018deriving">2018</a>)</span> propose a novel approach based on preposition semantic analysis network, where a preposition is the word that defines the relationship between two neighbouring words. In the case of patents, prepositions aid in revealing the relationships between keywords related to technologies. Patent documents largely consist of technical terms and, if the relationships between the keywords are well identified, the keyword analysis can be a useful tool for revealing the overall technological structure of the invention and the technological landscape.</p>
</div>
<div id="a-map-for-lexicons-design" class="section level2">
<h2><span class="header-section-number">13.3</span> A Map for Lexicons Design</h2>
<p>After the identification of the main techniques for dictionaries construction and for NER techniques used in the 23 papers, techniques were grouped into three classes: pre-processing tools, NER supervised tools and NER unsupervised tools. Table presented in figure <a href="sotadocumentsunderstandlexicons.html#fig:lexdesign">13.1</a> shows what of these techniques were used in the analysed papers. In the table, there is also a column that indicates the presence of expert intervention, a column that indicates the year of publication of papers and a column that gives an indication about the number of documents used as datasets for the analysis described in papers.</p>
<div class="figure" style="text-align: center"><span id="fig:lexdesign"></span>
<img src="_bookdown_files/figures/final_lexicon.pdf" alt="Summary of state-of-art techniques for lexicons design." width="80%" />
<p class="caption">
Figure 13.1: Summary of state-of-art techniques for lexicons design.
</p>
</div>
<p>The use of experts for crafting of Knowledge Base and Technical lexicons has evolved in time: at first, knowledge extraction was a completely human task in which domain experts selected manually keywords from raw texts. To date, with the development of text mining techniques just described, experts’ intervention has been reduced but not eliminated: although their intervention is considered too subjective, expensive and time-consuming, their contribution is still fundamental in the process of keywords selection and filtering, and in phase of dictionaries check and analysis check.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-song2015developing">
<p>Song, Min, Hwanjo Yu, and Wook-Shin Han. 2015. “Developing a Hybrid Dictionary-Based Bio-Entity Recognition Technique.” <em>BMC Medical Informatics and Decision Making</em> 15 (1). BioMed Central: S9.</p>
</div>
<div id="ref-yang2015hybrid">
<p>Yang, Hui, and Jonathan M Garibaldi. 2015. “A Hybrid Model for Automatic Identification of Risk Factors for Heart Disease.” <em>Journal of Biomedical Informatics</em> 58. Elsevier: S171–S182.</p>
</div>
<div id="ref-arif2017extracting">
<p>Arif-Uz-Zaman, Kazi, Michael E Cholette, Lin Ma, and Azharul Karim. 2017. “Extracting Failure Time Data from Industrial Maintenance Records Using Text Mining.” <em>Advanced Engineering Informatics</em> 33. Elsevier: 388–96.</p>
</div>
<div id="ref-joung2017monitoring">
<p>Joung, Junegak, and Kwangsoo Kim. 2017. “Monitoring Emerging Technologies for Technology Planning Using Technical Keyword Based Analysis from Patent Data.” <em>Technological Forecasting and Social Change</em> 114. Elsevier: 281–92.</p>
</div>
<div id="ref-rezaeian2017science">
<p>Rezaeian, Mina, H Montazeri, and RCGM Loonen. 2017. “Science Foresight Using Life-Cycle Analysis, Text Mining and Clustering: A Case Study on Natural Ventilation.” <em>Technological Forecasting and Social Change</em> 118. Elsevier: 270–80.</p>
</div>
<div id="ref-amado2018research">
<p>Amado, Alexandra, Paulo Cortez, Paulo Rita, and Sérgio Moro. 2018. “Research Trends on Big Data in Marketing: A Text Mining and Topic Modeling Based Literature Analysis.” <em>European Research on Management and Business Economics</em> 24 (1). Elsevier: 1–7.</p>
</div>
<div id="ref-baechle2017big">
<p>Baechle, Christopher, Ankur Agarwal, and Xingquan Zhu. 2017. “Big Data Driven Co-Occurring Evidence Discovery in Chronic Obstructive Pulmonary Disease Patients.” <em>Journal of Big Data</em> 4 (1). Springer: 9.</p>
</div>
<div id="ref-chen2017revealing">
<p>Chen, Qian, Ni Ai, Jie Liao, Xin Shao, Yufeng Liu, and Xiaohui Fan. 2017. “Revealing Topics and Their Evolution in Biomedical Literature Using Bio-Dtm: A Case Study of Ginseng.” <em>Chinese Medicine</em> 12 (1). BioMed Central: 27.</p>
</div>
<div id="ref-karystianis2017evaluation">
<p>Karystianis, George, Kristina Thayer, Mary Wolfe, and Guy Tsafnat. 2017. “Evaluation of a Rule-Based Method for Epidemiological Document Classification Towards the Automation of Systematic Reviews.” <em>Journal of Biomedical Informatics</em> 70. Elsevier: 27–34.</p>
</div>
<div id="ref-sasaki2008make">
<p>Sasaki, Yutaka, Yoshimasa Tsuruoka, John McNaught, and Sophia Ananiadou. 2008. “How to Make the Most of Ne Dictionaries in Statistical Ner.” <em>BMC Bioinformatics</em> 9 (11). BioMed Central: S5.</p>
</div>
<div id="ref-xu2009named">
<p>Xu, Gu, Shuang-Hong Yang, and Hang Li. 2009. “Named Entity Mining from Click-Through Data Using Weakly Supervised Latent Dirichlet Allocation.” In <em>Proceedings of the 15th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 1365–74. ACM.</p>
</div>
<div id="ref-mahalakshmi2018named">
<p>Mahalakshmi, Guruvayur, Vani Vijayan, and Betina Antony. 2018. “Named Entity Recognition for Automated Test Case Generation.” <em>INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY</em> 15 (1). ZARKA PRIVATE UNIV COLL COMPUTING &amp; INFORMATION SOC, PO BOX 132222, ZARQA, 13132, JORDAN: 112–20.</p>
</div>
<div id="ref-konkol2015latent">
<p>Konkol, Michal, Tomáš Brychcín, and Miloslav Konopík. 2015. “Latent Semantics in Named Entity Recognition.” <em>Expert Systems with Applications</em> 42 (7). Elsevier: 3470–9.</p>
</div>
<div id="ref-liu2015effects">
<p>Liu, Shengyu, Buzhou Tang, Qingcai Chen, and Xiaolong Wang. 2015. “Effects of Semantic Features on Machine Learning-Based Drug Name Recognition Systems: Word Embeddings Vs. Manually Constructed Dictionaries.” <em>Information</em> 6 (4). Multidisciplinary Digital Publishing Institute: 848–65.</p>
</div>
<div id="ref-song2015pkde4j">
<p>Song, Min, Won Chul Kim, Dahee Lee, Go Eun Heo, and Keun Young Kang. 2015. “PKDE4J: Entity and Relation Extraction for Public Knowledge Discovery.” <em>Journal of Biomedical Informatics</em> 57. Elsevier: 320–32.</p>
</div>
<div id="ref-murugesan2017bcc">
<p>Murugesan, Gurusamy, Sabenabanu Abdulkadhar, Balu Bhasuran, and Jeyakumar Natarajan. 2017. “BCC-Ner: Bidirectional, Contextual Clues Named Entity Tagger for Gene/Protein Mention Recognition.” <em>EURASIP Journal on Bioinformatics and Systems Biology</em> 2017 (1). Nature Publishing Group: 7.</p>
</div>
<div id="ref-basaldella2017entity">
<p>Basaldella, Marco, Lenz Furrer, Carlo Tasso, and Fabio Rinaldi. 2017. “Entity Recognition in the Biomedical Domain Using a Hybrid Approach.” <em>Journal of Biomedical Semantics</em> 8 (1). BioMed Central: 51.</p>
</div>
<div id="ref-unanue2017recurrent">
<p>Unanue, Iñigo Jauregi, Ehsan Zare Borzeshi, and Massimo Piccardi. 2017. “Recurrent Neural Networks with Specialized Word Embeddings for Health-Domain Named-Entity Recognition.” <em>Journal of Biomedical Informatics</em> 76. Elsevier: 102–9.</p>
</div>
<div id="ref-huang2018novel">
<p>Huang, Changqin, Jia Zhu, Xiaodi Huang, Min Yang, Gabriel Fung, and Qintai Hu. 2018. “A Novel Approach for Entity Resolution in Scientific Documents Using Context Graphs.” <em>Information Sciences</em> 432. Elsevier: 431–41.</p>
</div>
<div id="ref-remolona2017hybrid">
<p>Remolona, Miguel Francisco M, Matthew F Conway, Sriram Balasubramanian, Linxi Fan, Ziyan Feng, Tianhao Gu, Hyungtae Kim, et al. 2017. “Hybrid Ontology-Learning Materials Engineering System for Pharmaceutical Products: Multi-Label Entity Recognition and Concept Detection.” <em>Computers &amp; Chemical Engineering</em> 107. Elsevier: 49–60.</p>
</div>
<div id="ref-gupta2018automatic">
<p>Gupta, Anupama, Imon Banerjee, and Daniel L Rubin. 2018. “Automatic Information Extraction from Unstructured Mammography Reports Using Distributed Semantics.” <em>Journal of Biomedical Informatics</em> 78. Elsevier: 78–86.</p>
</div>
<div id="ref-wang2018information">
<p>Wang, Chengbin, Xiaogang Ma, Jianguo Chen, and Jingwen Chen. 2018. “Information Extraction and Knowledge Graph Construction from Geoscience Literature.” <em>Computers &amp; Geosciences</em> 112. Elsevier: 112–20.</p>
</div>
<div id="ref-an2018deriving">
<p>An, Jaehyeong, Kyuwoong Kim, Letizia Mortara, Sungjoo Lee, and others. 2018. “Deriving Technology Intelligence from Patents: Preposition-Based Semantic Analysis.” <em>Journal of Informetrics</em> 12 (1). Elsevier: 217–36.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="defining-industry-4-0-professional-archetypes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="future-developments.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["thesis_source.pdf", "thesis_source.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
