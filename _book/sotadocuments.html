<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Mining Technical Knowledge from Texts</title>
  <meta name="description" content="This document contains the PhD thesis of Filippo Chiarello.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Mining Technical Knowledge from Texts" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This document contains the PhD thesis of Filippo Chiarello." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Mining Technical Knowledge from Texts" />
  
  <meta name="twitter:description" content="This document contains the PhD thesis of Filippo Chiarello." />
  

<meta name="author" content="Filippo Chiarello">


<meta name="date" content="2018-10-02">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="sotatools.html">
<link rel="next" href="patents.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Text Mining Techniques for Knowledge Extraction from Technical Documents</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="goal.html"><a href="goal.html"><i class="fa fa-check"></i><b>1</b> Goal</a></li>
<li class="chapter" data-level="2" data-path="problem.html"><a href="problem.html"><i class="fa fa-check"></i><b>2</b> Problem</a></li>
<li class="chapter" data-level="3" data-path="solutions.html"><a href="solutions.html"><i class="fa fa-check"></i><b>3</b> Solutions</a></li>
<li class="chapter" data-level="4" data-path="research-questions.html"><a href="research-questions.html"><i class="fa fa-check"></i><b>4</b> Research Questions</a></li>
<li class="chapter" data-level="5" data-path="stakeholders.html"><a href="stakeholders.html"><i class="fa fa-check"></i><b>5</b> Stakeholders</a></li>
<li class="chapter" data-level="6" data-path="knowledge-intensive-manegement-engineering.html"><a href="knowledge-intensive-manegement-engineering.html"><i class="fa fa-check"></i><b>6</b> Knowledge Intensive Manegement Engineering</a></li>
<li class="part"><span><b>II State of the Art</b></span></li>
<li class="chapter" data-level="7" data-path="sotatools.html"><a href="sotatools.html"><i class="fa fa-check"></i><b>7</b> Phases, Tasks, and Techniques</a><ul>
<li class="chapter" data-level="7.1" data-path="sotatools.html"><a href="sotatools.html#sotatoolsprogram"><i class="fa fa-check"></i><b>7.1</b> Program</a></li>
<li class="chapter" data-level="7.2" data-path="sotatools.html"><a href="sotatools.html#sotatoolsimport"><i class="fa fa-check"></i><b>7.2</b> Import</a><ul>
<li class="chapter" data-level="7.2.1" data-path="sotatools.html"><a href="sotatools.html#sotatoolsimportretrieval"><i class="fa fa-check"></i><b>7.2.1</b> Document Retrieval</a></li>
<li class="chapter" data-level="7.2.2" data-path="sotatools.html"><a href="sotatools.html#sotatoolsimportformat"><i class="fa fa-check"></i><b>7.2.2</b> Documents Format</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="sotatools.html"><a href="sotatools.html#sotatoolstidy"><i class="fa fa-check"></i><b>7.3</b> Tidy</a></li>
<li class="chapter" data-level="7.4" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransform"><i class="fa fa-check"></i><b>7.4</b> Transform</a><ul>
<li class="chapter" data-level="7.4.1" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformsentencesplit"><i class="fa fa-check"></i><b>7.4.1</b> Sentence Splitting</a></li>
<li class="chapter" data-level="7.4.2" data-path="sotatools.html"><a href="sotatools.html#tokenization"><i class="fa fa-check"></i><b>7.4.2</b> Tokenization</a></li>
<li class="chapter" data-level="7.4.3" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformstemming"><i class="fa fa-check"></i><b>7.4.3</b> Stemming</a></li>
<li class="chapter" data-level="7.4.4" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformlemmatisation"><i class="fa fa-check"></i><b>7.4.4</b> Lemmatisation</a></li>
<li class="chapter" data-level="7.4.5" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformwi"><i class="fa fa-check"></i><b>7.4.5</b> Words importance metrics</a></li>
<li class="chapter" data-level="7.4.6" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformpos"><i class="fa fa-check"></i><b>7.4.6</b> Part-of-Speech Tagging</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodel"><i class="fa fa-check"></i><b>7.5</b> Model</a><ul>
<li class="chapter" data-level="7.5.1" data-path="sotatools.html"><a href="sotatools.html#sotatoolstransformngrams"><i class="fa fa-check"></i><b>7.5.1</b> N-Grams</a></li>
<li class="chapter" data-level="7.5.2" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodeldocclass"><i class="fa fa-check"></i><b>7.5.2</b> Document Classification</a></li>
<li class="chapter" data-level="7.5.3" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodelsentanal"><i class="fa fa-check"></i><b>7.5.3</b> Sentiment Analsysis</a></li>
<li class="chapter" data-level="7.5.4" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodelnetanal"><i class="fa fa-check"></i><b>7.5.4</b> Text Clustering</a></li>
<li class="chapter" data-level="7.5.5" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodelner"><i class="fa fa-check"></i><b>7.5.5</b> Named Entity Recognition</a></li>
<li class="chapter" data-level="7.5.6" data-path="sotatools.html"><a href="sotatools.html#sotatoolsmodeltopicmodel"><i class="fa fa-check"></i><b>7.5.6</b> Topic Modelling</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="sotatools.html"><a href="sotatools.html#sotatoolsvisualize"><i class="fa fa-check"></i><b>7.6</b> Visualize</a><ul>
<li class="chapter" data-level="7.6.1" data-path="sotatools.html"><a href="sotatools.html#the-grammar-of-graphics"><i class="fa fa-check"></i><b>7.6.1</b> The Grammar of Graphics</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="sotatools.html"><a href="sotatools.html#sotatoolscomunicate"><i class="fa fa-check"></i><b>7.7</b> Comunicate</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="sotadocuments.html"><a href="sotadocuments.html"><i class="fa fa-check"></i><b>8</b> Documents</a><ul>
<li class="chapter" data-level="8.1" data-path="sotadocuments.html"><a href="sotadocuments.html#sotadocumentsunderstand"><i class="fa fa-check"></i><b>8.1</b> Understand</a><ul>
<li class="chapter" data-level="8.1.1" data-path="sotadocuments.html"><a href="sotadocuments.html#domain-expertise"><i class="fa fa-check"></i><b>8.1.1</b> Domain Expertise</a></li>
<li class="chapter" data-level="8.1.2" data-path="sotadocuments.html"><a href="sotadocuments.html#sotadocumentsunderstandbyas"><i class="fa fa-check"></i><b>8.1.2</b> The problem of byases</a></li>
<li class="chapter" data-level="8.1.3" data-path="sotadocuments.html"><a href="sotadocuments.html#sotadocumentsunderstandlexicons"><i class="fa fa-check"></i><b>8.1.3</b> The Importance of Lexicons for Technical Documents Analysis</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sotadocuments.html"><a href="sotadocuments.html#sotadocumentspatents"><i class="fa fa-check"></i><b>8.2</b> Patents</a><ul>
<li class="chapter" data-level="8.2.1" data-path="sotadocuments.html"><a href="sotadocuments.html#metadata-approaches"><i class="fa fa-check"></i><b>8.2.1</b> Metadata Approaches</a></li>
<li class="chapter" data-level="8.2.2" data-path="sotadocuments.html"><a href="sotadocuments.html#keywords-approaches"><i class="fa fa-check"></i><b>8.2.2</b> Keywords Approaches</a></li>
<li class="chapter" data-level="8.2.3" data-path="sotadocuments.html"><a href="sotadocuments.html#natural-language-processing-approaches"><i class="fa fa-check"></i><b>8.2.3</b> Natural Language Processing approaches</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="sotadocuments.html"><a href="sotadocuments.html#sotadocumentspapers"><i class="fa fa-check"></i><b>8.3</b> Papers</a></li>
<li class="chapter" data-level="8.4" data-path="sotadocuments.html"><a href="sotadocuments.html#sotadocumentswiki"><i class="fa fa-check"></i><b>8.4</b> Wikipedia</a></li>
<li class="chapter" data-level="8.5" data-path="sotadocuments.html"><a href="sotadocuments.html#sotadocumentstwitter"><i class="fa fa-check"></i><b>8.5</b> Social Media</a><ul>
<li class="chapter" data-level="8.5.1" data-path="sotadocuments.html"><a href="sotadocuments.html#economics"><i class="fa fa-check"></i><b>8.5.1</b> Economics</a></li>
<li class="chapter" data-level="8.5.2" data-path="sotadocuments.html"><a href="sotadocuments.html#marketing"><i class="fa fa-check"></i><b>8.5.2</b> Marketing</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Methods and Results</b></span></li>
<li class="chapter" data-level="9" data-path="patents.html"><a href="patents.html"><i class="fa fa-check"></i><b>9</b> Patents</a><ul>
<li class="chapter" data-level="9.1" data-path="patents.html"><a href="patents.html#usersresults"><i class="fa fa-check"></i><b>9.1</b> Users</a><ul>
<li class="chapter" data-level="9.1.1" data-path="patents.html"><a href="patents.html#method"><i class="fa fa-check"></i><b>9.1.1</b> Method</a></li>
<li class="chapter" data-level="9.1.2" data-path="patents.html"><a href="patents.html#results"><i class="fa fa-check"></i><b>9.1.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="patents.html"><a href="patents.html#advdrwresults"><i class="fa fa-check"></i><b>9.2</b> Advantages and Drawbacks</a><ul>
<li class="chapter" data-level="9.2.1" data-path="patents.html"><a href="patents.html#methodology"><i class="fa fa-check"></i><b>9.2.1</b> Methodology</a></li>
<li class="chapter" data-level="9.2.2" data-path="patents.html"><a href="patents.html#results-1"><i class="fa fa-check"></i><b>9.2.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="patents.html"><a href="patents.html#trademakrs"><i class="fa fa-check"></i><b>9.3</b> Trademakrs</a><ul>
<li class="chapter" data-level="9.3.1" data-path="patents.html"><a href="patents.html#methodology-1"><i class="fa fa-check"></i><b>9.3.1</b> Methodology</a></li>
<li class="chapter" data-level="9.3.2" data-path="patents.html"><a href="patents.html#results-2"><i class="fa fa-check"></i><b>9.3.2</b> Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="papers.html"><a href="papers.html"><i class="fa fa-check"></i><b>10</b> Papers</a><ul>
<li class="chapter" data-level="10.1" data-path="papers.html"><a href="papers.html#sustainable-manufacturing-an-analysis-of-the-6r-framework"><i class="fa fa-check"></i><b>10.1</b> Sustainable Manufacturing: an Analysis of the 6R Framework</a><ul>
<li class="chapter" data-level="10.1.1" data-path="papers.html"><a href="papers.html#methodology-2"><i class="fa fa-check"></i><b>10.1.1</b> Methodology</a></li>
<li class="chapter" data-level="10.1.2" data-path="papers.html"><a href="papers.html#results-3"><i class="fa fa-check"></i><b>10.1.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="papers.html"><a href="papers.html#sustainable-manufacturing-an-extended-mapping"><i class="fa fa-check"></i><b>10.2</b> Sustainable Manufacturing: An Extended Mapping</a><ul>
<li class="chapter" data-level="10.2.1" data-path="papers.html"><a href="papers.html#methodology-3"><i class="fa fa-check"></i><b>10.2.1</b> Methodology</a></li>
<li class="chapter" data-level="10.2.2" data-path="papers.html"><a href="papers.html#results-4"><i class="fa fa-check"></i><b>10.2.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="papers.html"><a href="papers.html#blockchain"><i class="fa fa-check"></i><b>10.3</b> Blockchain</a><ul>
<li class="chapter" data-level="10.3.1" data-path="papers.html"><a href="papers.html#methodology-4"><i class="fa fa-check"></i><b>10.3.1</b> Methodology</a></li>
<li class="chapter" data-level="10.3.2" data-path="papers.html"><a href="papers.html#results-5"><i class="fa fa-check"></i><b>10.3.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="papers.html"><a href="papers.html#precision-agriculture"><i class="fa fa-check"></i><b>10.4</b> Precision Agriculture</a><ul>
<li class="chapter" data-level="10.4.1" data-path="papers.html"><a href="papers.html#methodology-5"><i class="fa fa-check"></i><b>10.4.1</b> Methodology</a></li>
<li class="chapter" data-level="10.4.2" data-path="papers.html"><a href="papers.html#results-6"><i class="fa fa-check"></i><b>10.4.2</b> Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="wikipedia.html"><a href="wikipedia.html"><i class="fa fa-check"></i><b>11</b> Wikipedia</a><ul>
<li class="chapter" data-level="11.1" data-path="wikipedia.html"><a href="wikipedia.html#technimetrochap"><i class="fa fa-check"></i><b>11.1</b> Industry 4.0: Extracting and Mapping Technologies</a><ul>
<li class="chapter" data-level="11.1.1" data-path="wikipedia.html"><a href="wikipedia.html#methodology-6"><i class="fa fa-check"></i><b>11.1.1</b> Methodology</a></li>
<li class="chapter" data-level="11.1.2" data-path="wikipedia.html"><a href="wikipedia.html#results-7"><i class="fa fa-check"></i><b>11.1.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="wikipedia.html"><a href="wikipedia.html#industry-4.0-a-comparison-with-industrie-4.0"><i class="fa fa-check"></i><b>11.2</b> Industry 4.0: a Comparison with Industrie 4.0</a><ul>
<li class="chapter" data-level="11.2.1" data-path="wikipedia.html"><a href="wikipedia.html#methodology-7"><i class="fa fa-check"></i><b>11.2.1</b> Methodology</a></li>
<li class="chapter" data-level="11.2.2" data-path="wikipedia.html"><a href="wikipedia.html#results-8"><i class="fa fa-check"></i><b>11.2.2</b> Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="social-media.html"><a href="social-media.html"><i class="fa fa-check"></i><b>12</b> Social Media</a><ul>
<li class="chapter" data-level="12.1" data-path="social-media.html"><a href="social-media.html#technical-sentiment-analysis"><i class="fa fa-check"></i><b>12.1</b> Technical Sentiment Analysis</a><ul>
<li class="chapter" data-level="12.1.1" data-path="social-media.html"><a href="social-media.html#methodology-8"><i class="fa fa-check"></i><b>12.1.1</b> Methodology</a></li>
<li class="chapter" data-level="12.1.2" data-path="social-media.html"><a href="social-media.html#results-9"><i class="fa fa-check"></i><b>12.1.2</b> Results</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Impacts and Future Developments</b></span></li>
<li class="chapter" data-level="13" data-path="policy-making.html"><a href="policy-making.html"><i class="fa fa-check"></i><b>13</b> Policy Making</a><ul>
<li class="chapter" data-level="13.1" data-path="policy-making.html"><a href="policy-making.html#impact-of-research-from-the-perspective-of-users."><i class="fa fa-check"></i><b>13.1</b> Impact of research from the perspective of users.</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="marketing-1.html"><a href="marketing-1.html"><i class="fa fa-check"></i><b>14</b> Marketing</a><ul>
<li class="chapter" data-level="14.1" data-path="marketing-1.html"><a href="marketing-1.html#the-user-side-of-competition"><i class="fa fa-check"></i><b>14.1</b> The User Side of Competition</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="research-and-development.html"><a href="research-and-development.html"><i class="fa fa-check"></i><b>15</b> Research and Development</a><ul>
<li class="chapter" data-level="15.1" data-path="research-and-development.html"><a href="research-and-development.html#clustering-technologies-keywords-topic-modeling-enriched-dictionaries"><i class="fa fa-check"></i><b>15.1</b> Clustering technologies: Keywords, topic modeling, enriched dictionaries</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="design.html"><a href="design.html"><i class="fa fa-check"></i><b>16</b> Design</a><ul>
<li class="chapter" data-level="16.1" data-path="design.html"><a href="design.html#exploiting-patent-information-in-novel-ways"><i class="fa fa-check"></i><b>16.1</b> Exploiting patent information in novel ways</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="human-resources.html"><a href="human-resources.html"><i class="fa fa-check"></i><b>17</b> Human Resources</a><ul>
<li class="chapter" data-level="17.1" data-path="human-resources.html"><a href="human-resources.html#defining-industry-4.0-professional-archetypes"><i class="fa fa-check"></i><b>17.1</b> Defining industry 4.0 professional archetypes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i>Conclusions</a></li>
<li class="chapter" data-level="" data-path="glossary.html"><a href="glossary.html"><i class="fa fa-check"></i>Glossary</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mining Technical Knowledge from Texts</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sotadocuments" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Documents</h1>
<p>In this section contains a review of the main classes of technical documents analyzed in the present work. The documents are patents, papers, Wikipedia, Social Media, Publicly Funded Projects and Human Resources Documentation. Before starting to analyze the state of the art techniques to perform knowledge extraction for these documents, the focus is on a task that has intentionally not been analyzed in section <a href="sotatools.html#sotatools">7</a>: understanding.</p>
<div id="sotadocumentsunderstand" class="section level2">
<h2><span class="header-section-number">8.1</span> Understand</h2>
<p>The most difficult challenge in technology intelligence is not how to detect the large trends- they are visible anyway. It is, rather, how to detect weak signals, or information that initially appears with low frequency, in unrelated or unexpected regions of the technology landscape, and associated with large noise (Apreda et al. 2016). These signals escape from traditional statistical detection techniques, exactly because it is difficult to distinguish them from pure statistical noise. Metadata are not the appropriate source of data for detecting weak signals. As a matter of fact, they can be detected only by using a fine-grained domain knowledge structure, or using the full text of documents. As an example, classification-based clustering has been shown to be flawed because the patent class used is usually only the first one listed in patents, generating loss of granularity (Benner and Waldfogel, 2008; Aharonson and Schilling, 2016).</p>
<p>Hypothesis</p>
<p>postulation</p>
<div id="domain-expertise" class="section level3">
<h3><span class="header-section-number">8.1.1</span> Domain Expertise</h3>
<p>(collins)</p>
<p>Sheela Jasanow</p>
<p>Taleb?</p>
</div>
<div id="sotadocumentsunderstandbyas" class="section level3">
<h3><span class="header-section-number">8.1.2</span> The problem of byases</h3>
<p>Each site typically contains a huge volume of opinionated text that is not always easily deciphered in long forum postings and blogs. The average human reader will have difficulty identifying relevant sites and accurately summarizing the information and opinions contained in them. Moreover, it is also known that human analysis of text information is subject to considerable biases, e.g., people often pay greater attention to opinions that are consistent with their own preferences. People also have difficulty, owing to their mental and physical limitations, producing consistent results when the amount of information to be processed is large. Automated opinion mining and summarization systems are thus needed, as subjective biases and mental limitations can be overcome with an objective sentiment analysis system.</p>
</div>
<div id="sotadocumentsunderstandlexicons" class="section level3">
<h3><span class="header-section-number">8.1.3</span> The Importance of Lexicons for Technical Documents Analysis</h3>
</div>
</div>
<div id="sotadocumentspatents" class="section level2">
<h2><span class="header-section-number">8.2</span> Patents</h2>
<p>Nowadays patent data can be used for planning technological strategy <span class="citation">(Ernst <a href="#ref-ernst2003patent">2003</a>)</span>. The focus on the technological usefulness of patent data is certainly a great advantage, but this huge research area could hide other useful application for patents. For example, in <span class="citation">(Jin, Jeong, and Yoon <a href="#ref-jin2015technology">2015</a>)</span> the authors consider on one side patents as a source to collect information about technologies and products, and on the other side manuals, handbooks and market reports to collect market information. Since patents are only technological documents many potential patent reader (e.g. designers, marketers) could be taken aside. Despite this problem, some researchers <span class="citation">(Bonino, Ciaramella, and Corno <a href="#ref-bonino2010review">2010</a>)</span> affirm that there is an increasing variety of readers: not only technician and researchers but also marketers and designers who have grown an interest in patent analysis. Nevertheless, to our knowledge there are no researches that aim at facilitating information extraction for non-technological focused patent readers.</p>
<p>The bias that patent are only tech-oriented documents is due to two main reasons:</p>
<ul>
<li>Patents are produced to disclose and protect an invention, their content is mainly technical and legal.</li>
<li>80% of technical information is not available elsewhere <span class="citation">(Terragno <a href="#ref-terragno1979">1979</a>)</span>, so patents are one of the most comprehensive resources for technical analysis.</li>
</ul>
<p>Focusing on the second point, our hypothesis is that also a fraction of all the other kinds of information (e.g. marketing and sociological information ) is not contained elsewhere and it will appear in public documents (e.g. manual handbooks and market reports) in 6-18 months <span class="citation">(Golzio <a href="#ref-golzio2012">2012</a>)</span>.</p>
<p>Unfortunately there are four aspects reducing the non-tech readers’ ability to analyze patents efficiently. First of all, an increasingly high number of patent filings generates a massive information overflow [<span class="citation">Bergmann et al. (<a href="#ref-bergmann2008evaluating">2008</a>)</span>; secondly, analyzing patents takes a long time and requires skilled personnel <span class="citation">(Liang and Tan <a href="#ref-liang2007text">2007</a>)</span>; the quality of patent assessment process is decreasing <span class="citation">(Burke and Reitzig <a href="#ref-burke2007">2007</a>, <span class="citation">Philipp (<a href="#ref-philipp2006">2006</a>)</span>)</span> because of the reduced assessment time available for patent examiners; finally, activities like patent hiding, proliferation and bombing, contribute to the generation of confusion and to the loss of time in research and analysis phases <span class="citation">(Fantoni et al. <a href="#ref-fantoni2013automatic">2013</a>)</span>. These problems affect non-tech oriented patent readers as well as typical readers, even though the impact may be stronger on the firsts.</p>
<p>The main difference between typical and non-tech patent readers is the information they focus on. <em>Patent attorneys</em> and <em>Intellectual Property (IP) managers</em> are interested in reading patents for legal reasons to orient the IP direction. Analyzing patents is the core of their work, so they are experts in finding the information they need. Furthermore, they can spend most of their work-time on the activity. On the other hand, usually <em>marketers and designers</em> (taken as example of non-tech oriented readers) search users’ behavioral changes and needs, market trends, designers’ vision, R&amp;D trends and competitors’ strategies. In addition, they rarely work with patents, so they do not know what and how to search. Lastly, they have short time to spend on the activity, and they waste most of this time understanding the legal and technical jargon used in patents.</p>
<p>Due to the large amount of information contained in patents and the growing interest to exploit this information, huge efforts have been devoted to the development of systems source to automatically extract different kind of information from such an enormous and valuable data.</p>
<p>Many techniques introduced in order to extract textual information from patents come from extensive research advances in the Natural Language Processing field (NLP). NLP is an area of research and artificial intelligence which aims at teaching computers to understand and manipulate natural language text in order to performs different tasks such as information extraction, machine translation and sentiment analysis.</p>
<p>The field of technology intelligence has become so large in recent years that several efforts to review and summarize the various approaches have been undertaken <span class="citation">(Abbas, Zhang, and Khan <a href="#ref-abbas2014literature">2014</a>)</span>. There are several possible ways to classify the approaches. For example a used classification distinguish between Visualization techniques (Patent networks, Clustering) and Text mining (NLP-based, Property-function, Rule-based, Semantic analysis, Neural networks). Another possible classification is:</p>
<ul>
<li><p><em>Metadata approaches</em>: methods that uses sources of information embedded in patents, such as claims structure or bibliographic information</p></li>
<li><p><em>Keyword approaches</em>: methods able to produce vector representations of the analyzed documents. Computed vectors can be used for many applications such as patent retrieval by keyword, or patent similarity matching. Even though this approach can be used for several tasks, it is not suitable to catch semantic relationships between entities in sentences. Furthermore, these methods use a blacklist to remove noisy words <span class="citation">(Blanchard <a href="#ref-blanchard2007understanding">2007</a>)</span> or use predefined lexicons <span class="citation">(Chiarello et al. <a href="#ref-chiarello2017product">2017</a>)</span>. The right design of such list dramatically impacts the final output of the analysis <span class="citation">(Sungjoo Lee, Yoon, and Park <a href="#ref-Lee2009">2009</a><a href="#ref-Lee2009">a</a>, <span class="citation">C. Lee, Kang, and Shin (<a href="#ref-Lee2015">2015</a><a href="#ref-Lee2015">a</a>)</span>, <span class="citation">Montecchi, Russo, and Liu (<a href="#ref-Montecchi2013">2013</a>)</span>)</span></p></li>
<li><p><em>Natural Language Processing approaches</em>: methods based on grammatical and syntactical structures extracted by natural language processing tools, such as Part-of-Speech taggers and syntactical parsers. Unlike the keyword based approach, these methods are able to capture the relationships between the entities mentioned in sentences <span class="citation">(J. Yoon, Park, and Kim <a href="#ref-Park20131">2013</a><a href="#ref-Park20131">a</a>,<span class="citation">Park, Yoon, and Kim (<a href="#ref-Park2011a">2011</a><a href="#ref-Park2011a">a</a>)</span>, <span class="citation">Park et al. (<a href="#ref-Park20133">2013</a>)</span>)</span>.</p></li>
</ul>
<p>Each approach allows to capture different types of information from patents and build a knowledge base which can be exploited by patent analysis tools. For this reason the right approach to be chosen to develop a patent analysis system depends on the task to be solved, on the information to be analyzed and on the computational resources involved to solve the task. Choosing a good trade-off between these factors is a strict requirement in particular when analyzing big patent sets.</p>
<div id="metadata-approaches" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Metadata Approaches</h3>
<p>Patent documents has the following metadata:</p>
<ul>
<li>Patent office</li>
<li>Inventors</li>
<li>Affiliation of the inventors</li>
<li>Filling date</li>
<li>Publication date</li>
<li>Address of the affiliation of the inventor</li>
<li>Patent classifications</li>
<li>References</li>
<li>Assignee</li>
<li>Affiliation of the assignee</li>
<li>Address of the affiliation of the assignee</li>
</ul>
<p>Furthermore they contain text content:</p>
<ul>
<li>Title</li>
<li>Abstract</li>
<li>Keyword</li>
<li>Summary page</li>
<li>Drawing set</li>
<li>Background of the invention</li>
<li>Brief summary of the invention</li>
<li>Brief description of the drawings</li>
<li>Detailed description of the invention</li>
<li>Claim set</li>
</ul>
<p>This does not mean that metadata allow a unique identification. Disambiguation of metadata remains a challenge in most cases. Only recently documents have started to include a unique identifier, following the cooperation among the main producers and users. The unique identifiers refer to the publication (DOI, Digital Object Identifier) or the author (author ID). However, metadata are written and stored in a standardized way, so that it is possible to categorize them. Issues of disambiguation refer mainly to the identity of individual entities (e.g. distinguish between two authors with exactly the same name and surname) but not of categories (e.g. distinguish between the name of an author and the name of a university).</p>
<p>Metadata approaches for patent analysis exploit three types of information:</p>
<ul>
<li>bibliometric information</li>
<li>patent structure information</li>
<li>patent review process information.</li>
</ul>
<p>In this approach are usually considered both patent and non-patent literature: for example patents with a high number of citations in papers usually indicate a strong correlation with the foundation of a technology.</p>
<p>On of the main problems addressed using metadata approaches is measure of the technology life cycle stage. The information about at which stage of maturity a technology is, is an important aspect taken into account by who decides to invest. Since the life cycle of a product is clearly related by patent grants evolution <span class="citation">(Andersen <a href="#ref-andersen1999hunt">1999</a>)</span>, this lead research to investigate on patent indices that can be considered as appropriate life cycle stage indicators. The main effort has been directed in the identification of the three different technology life cycle stages: introduction, growth and maturity <span class="citation">(Haupt, Kloyer, and Lange <a href="#ref-haupt2007patent">2007</a>)</span>. In this work, the author took into account that several studies have shown that a S-shape evolution of the number of patent applications or even a double-S-shape is typical. Consequently, the author defined the concept of patent activity index as an appropriate life cycle indicator only if its mean value differs significantly between the life cycle stages. The results of the work can be summarised as follow:</p>
<ol style="list-style-type: decimal">
<li>Backward literature citations increase significantly only at the transition from introduction to growth;</li>
<li>Backward patent citations increase significantly at both stage transitions;</li>
<li>The number of forward citations decreases significantly at the transition from introduction to growth;</li>
<li>The number of dependent claims is significantly higher at later technology life cycle stages than in earlier ones;</li>
<li>The number of priorities referred to in a patent application is significantly higher at later technology life cycle stages than in earlier ones;</li>
<li>Examination processes take longer in the phases of introduction and maturity than at the growth stage.</li>
</ol>
<p>The main limit of these methods is the need of assumptions for what concerns the shapes of the stages curves.</p>
<p>For this reason furthuter works introduced an unsupervised method able to automatically detect the number of life cycle stages and the transition times of the technology of interest <span class="citation">(Lee et al. <a href="#ref-lee2016stochastic">2016</a>)</span>. Here, seven time series patent indicator were taken into account:</p>
<ul>
<li>patent activity which allows to model the evolution of a pattern. In particular increasing and decreasing patterns are considered a change for what concerns the research and development activity;</li>
<li>the number of technology developers in the analyzed temporal series. It has been shown that a great number of competitor enters in the initial stages of a technology’s life cycle, but this number lowers in the matu- rity stage</li>
<li>the number of different patent application areas in the considered temporal series. This is an important indicator since it has been shown that the number of technology application areas are small in the first stages of their life cycles and in- creases in the later life cycle stages</li>
<li>the number of backward citations. It has been shown that patents with an high number of backward citations have less relevance with respect to the patents with a lower number of citations</li>
<li>the number of forward citations which expresses the technological value of a patent in the analyzed temporal period</li>
<li>the duration of examination processes as the average time between the filing and granting dates.</li>
<li>the number of claims belonging to the patent. The more the number of claims reported by the patents, the higher the correlation with novelty and the financial value is.</li>
</ul>
<p>Another widely adressed problem using metadata is citation analysis. Publications, patents, technical standards or clinical guidelines include a section in which other documents are cited. Citation analysis argues that including the reference to another document is the result of an intentional act, whose meaning may differ according to the type of document, but is nevertheless always worth of consideration <span class="citation">(Moed <a href="#ref-moed2006citation">2006</a>)</span>. The analysis of citations, initially developed in scientometrics and bibliometrics, has migrated to technology intelligence, following the initial concept of patent bibliometrics <span class="citation">(Narin <a href="#ref-narin1994patent">1994</a>)</span>. Patent (or firms, or inventors) that cite the same prior art are clustered together. Patent citation networks are then generated <span class="citation">(Karki <a href="#ref-karki1997patent">1997</a>, <span class="citation">Érdi et al. (<a href="#ref-erdi2013prediction">2013</a>)</span>)</span>. In fact, citations form a network structure, whose graph-theoretic properties can be interpreted in technology intelligence exercises <span class="citation">(Lee and Kim <a href="#ref-lee2017knowledge">2017</a>)</span>. Patent citation networks have properties of small world <span class="citation">(Cowan and Jonard <a href="#ref-cowan2004network">2004</a>)</span> and their degree follows a power law distribution <span class="citation">(Chen and Hicks <a href="#ref-chen2004tracing">2004</a>)</span>. Patent citation analysis can be used to identify trajectory patterns and technology structure and paths, that is, knowledge flows among firms and among subsectors of an industry. In standard citation analysis all citations are considered equal. This counting approach can be criticized because “it relies on the assumption that patents are equally significant” <span class="citation">(Gerken and Moehrle <a href="#ref-gerken2012new">2012</a>)</span>, which is in contrast with the empirical evidence on the large differences in patent value. This assumption is therefore removed in more advanced techniques in which the structure of citations from patents gets a qualification. It may be possible, however, that citations to other patents are strategically made by applicants, for example by citing their own patents or hiding other relevant citations). Backward citations may not be associated to technological novelty if they deliberately point only to the state of the art <span class="citation">(Rost <a href="#ref-rost2011strength">2011</a>)</span>. Citations introduced by examiners are also another potential source of bias <span class="citation">(Alcacer and Gittelman <a href="#ref-alcacer2006patent">2006</a>)</span>. Finally, it has been reported that the total number of citations increased over time, leading to “citation inflation” and the loss of value <span class="citation">(Hall, Jaffe, and Trajtenberg <a href="#ref-hall2001nber">2001</a>)</span>.</p>
<p>Derived from citation analysis, co-citation analysis argues that documents that are cited by the same documents should be considered part of the same cluster <span class="citation">(Small <a href="#ref-small2006tracking">2006</a>, <span class="citation">Small and Sweeney (<a href="#ref-small1985clustering">1985</a>)</span>)</span>. A variant of this technique, called author co-citation analysis <span class="citation">(White and Griffith <a href="#ref-white1981author">1981</a>)</span>, cluster documents that are cited by the same authors. Co-citation analysis can also be used to create classification systems of patents <span class="citation">(Lai and Wu <a href="#ref-lai2005using">2005</a>)</span>.</p>
</div>
<div id="keywords-approaches" class="section level3">
<h3><span class="header-section-number">8.2.2</span> Keywords Approaches</h3>
<p>In the keyword based approach each patent is represented as a vector where each component measure the importance of a specific keyword, like explained in section <a href="sotatools.html#sotatoolstransformwi">7.4.5</a>. The keywords to be taken into account depend on the patent set under analysis and on the goal of the task. Keywords can be extracted automatically using a text mining module, manually by experts or with hybrid methods where domain experts judge the relevance and the quality of the extracted keywords in order to limit the results to the most important keywords. Once keyword vectors are obtained, tasks such as patent similarity can be easily computed by using standard distance measures like cosine similarity. In addition, the keyword extraction allows to define more complex patent similarities measures <span class="citation">(Moehrle <a href="#ref-moehrle2010measures">2010</a>)</span> that can be exploited for the development of patent analysis tools <span class="citation">(Sungjoo Lee, Yoon, and Park <a href="#ref-lee2009approach">2009</a><a href="#ref-lee2009approach">b</a>,<span class="citation">C. Lee, Kang, and Shin (<a href="#ref-lee2015novelty">2015</a><a href="#ref-lee2015novelty">b</a>)</span>)</span> such as mappers or patent search engines. The main goal of these works is to developed systems for building keyword-based patent maps to be used for technology innovation activities. The system is composed of a text mining module, a patent mapping module and a patent vacancies identification module. Once a specific technology field is taken into account for analysis and a related patent set is extracted, the modules of the system are sequentially executed. The text mining module automatically identifies relevant keywords in each patent of the considered patent set. Once all the keywords are extracted, only the ones with the highest relevance are selected for a further screening by domain experts. The final set of keywords resulting from the screening process is then considered for building the patent keyword vectors on the considered patent set. Specifically each component of the patent vector holds the frequency the corresponding keyword in the considered patent. Once all the keyword vectors are computed, the patent mapping module is executed to generate the patent map. The mapping is calculated by executing the Principal Component Analysis (PCA) algorithm on all the vectors. The PCA method allows to map n-dimensional vectors on a rectangular planar surface in order to generate the patent map. Intuitively this method allows to find the most meaningful 2 dimensional projection that filters out the correlated components of a n-dimensional vectors. The result of applying this method over the patent keyword vectors is a meaningful patent mapping, in which each patent is mapped over a 2-dimensional surface. Once the patent map is computed, a vacancy detection module is executed on the patent map. The vacancy detection module identifies sparse areas which can be considered good candidates for a research investigation. For each interesting vacancy, a list of related patents is obtained by selecting the ones which are located on the region boundaries. On the calculated list, a set of information for each patent is computed. This information is used to capture the importance of a patent in this patent list. Features considered strong indicators of the relevance of each patent are the number of citations [38] and the number of average citations by patents in the patent list. Finally, emerging and declining keywords are computed by taking into account the time series analysis of the considered keywords in the patent list. This allows to identify promising technology trends that can considered for further investigation.</p>
<p>The metadata and keyword approaches has a long tradition but suffers from several limitations. First, the initial query based on keywords is usually produced by human experts, either on an individual basis or organized as a panel. In practice, one of the best skills of research centers or consultancies specialised in technology intelligence has been, in the past, the ability to mobilize high level experts on an international basis in order to produce well crafted query lists. Unfortunately these lists, even if they are produced following elicitation procedures that respect state of the art recommendations in social sciences, are inevitably biased. Experts are extremely good in their field, but are not better that others if they have to evaluate matters that are outside their domain <span class="citation">(Burgman <a href="#ref-burgman2015trusting">2015</a>)</span>. To the extent that emerging technologies are complex and fast evolving technologies, it is likely that experts have a narrow, or biased, perception of the dynamics. Experts tend to keep their existing R&amp;D areas in mind, have personal and organizational inclinations, are subject to halo effects in favor of well known institutions or solutions, and may follow different criteria for selecting promising technologies <span class="citation">(Kim and Bae <a href="#ref-kim2017novel">2017</a>)</span>. It has been shown that little differences in the wording of queries, or on the time window, may end up in completely different sets of documents, leading the analysis in different directions <span class="citation">(Bassecoulard, Lelu, and Zitt <a href="#ref-bassecoulard2007mapping">2007</a>)</span>. In addition to these authors, several studies in recent years have called the attention to the risk that initial differences in the delineation process generate non-comparable descriptions of technologies <span class="citation">(Mogoutov and Kahane <a href="#ref-mogoutov2007data">2007</a>,<span class="citation">Youtie, Shapira, and Porter (<a href="#ref-youtie2008nanotechnology">2008</a>)</span>, <span class="citation">Ghazinoory, Ameri, and Farnoodi (<a href="#ref-ghazinoory2013application">2013</a>)</span>)</span>. Following this line of concern,methodologies to update the keyword structure in an iterative, or evolutionary way has been proposed <span class="citation">(Mogoutov and Kahane <a href="#ref-mogoutov2007data">2007</a>)</span>. Second, it has been shown that when experts are asked to decide on relatedness measures (e.g. synonyms, hypernims or hyponims), they do not apply systematic rules <span class="citation">(Tseng, Lin, and Lin <a href="#ref-tseng2007text">2007</a>,<span class="citation">Noh, Jo, and Lee (<a href="#ref-noh2015keyword">2015</a>)</span>)</span>. Third, the query list is static. Once defined, it is used to extract documents from large corpora, which are then processed. In dynamic technologies, it is likely that the pace of technological changes exceeds the speed of updating of the query lists. It is difficult to convene panels of experts repeatedly, also because of the large costs incurred in expert selection and management <span class="citation">(Tseng, Lin, and Lin <a href="#ref-tseng2007text">2007</a>)</span>. As an example, with the advent of nanotechnology it was felt the need to introduce a new patent sub-class. The sub-class B82B was introduced in year 2000, but it did not incorporate the previous patents, so that a comparison across time is not feasible. A new sub-class, B82Y, was introduced in 2011 <span class="citation">(Kreuchauff and Korzinov <a href="#ref-kreuchauff2017patent">2017</a>)</span>.</p>
</div>
<div id="natural-language-processing-approaches" class="section level3">
<h3><span class="header-section-number">8.2.3</span> Natural Language Processing approaches</h3>
<p>The impressive advancements of computational linguistics in the last two decades have made it possible to carry out analysis on the full content, not only the metadata, of large collections of texts. In text mining patterns are extracted from unstructured collection of documents, while in the metadata approach the patterns are extracted from structured documents or databases. This has opened the way to the “full text based scientometrics” <span class="citation">(Boyack, Small, and Klavans <a href="#ref-boyack2013improving">2013</a>)</span> and has created the conditions for the convergence between the citationist approach illustrated above, and the lexical approach. Text mining techniques have then been applied to the corpus of patent texts, with a number of extremely powerful results <span class="citation">(Tseng, Lin, and Lin <a href="#ref-tseng2007text">2007</a>, <span class="citation">Joung and Kim (<a href="#ref-joung2017monitoring">2017</a>)</span>, <span class="citation">Kreuchauff and Korzinov (<a href="#ref-kreuchauff2017patent">2017</a>)</span>, <span class="citation">Ozcan and Islam (<a href="#ref-ozcan2017patent">2017</a>)</span>; Yoon and Kim <a href="#ref-yoon2012detecting">2012</a>)</span>. In turn, text mining can be applied for the search of specific words (or combination thereof) or in the search for patterns that are not defined ex ante. In the former case the most used techniques are combination of keywords, correspondence analysis or category specific terms. These approaches expand the search over the full text of patents but preserve the limitations of keyword-based search. On the contrary, the search for patterns is the object of the most largely used technique, namely topic modelling. Pattern recognition in patent texts is “still in its infancy” <span class="citation">(Madani and Weber <a href="#ref-madani2016evolution">2016</a>)</span> but its applications are growing rapidly. A useful review of NLP techniques in patent analysis <span class="citation">(Madani and Weber <a href="#ref-madani2016evolution">2016</a>)</span> identifies:</p>
<ul>
<li>the statistical approach that uses the Term Frequency-Inverted Document Frequency (TF-IDF) method to detect regularities</li>
<li>the semantic approach uses SAO (Subject-Action-Object) and property-function structures in order to attribute meaning to the texts</li>
<li>the corpus approach adopts ontology-based techniques.</li>
</ul>
<p>In turn, all these three information retrieval approaches can be extended by using pattern recognition techniques, that are keyword-, patent- or concept-based.</p>
<p>Text mining has several limitations : it cannot consider synonyms and the co-occurrence of keywords, while the inclusion of compound words and n-gram expressions requires large computational power. In addition, in the case of patents, claims are written in “arcane legalese” in order to hide critical elements and confound potential competitors. The challenge here is how to maximize the substantive knowledge that can be generated by automatic processing of the full text. It has been remarked since long time that a promising direction for research into technology intelligence and foresight lies in the combination of methods. This recommendation requires the combination between domain-knowledge and powerful computational approaches. It is this combination that holds the best promise to generate methods for the identification of emerging technologies, and more generally, for technology intelligence, that are able to identify high-granularity information producing weak signals, that is, to distinguish accurately the signal from the noise in turbulent and dynamic technological landscapes.</p>
<p>By exploiting the information obtained by these steps, several information extraction tasks can be solved by other NLP tools such as: - Term extraction: the task of automatically extract relevant terms from a given corpus. Part of Speech tags are typically used by term extractors to narrow the terms search to a predefined term structure; - Named entity recognition: the task of automatically identify and classify named entities in text such as persons, organizations and locations. Named entity recognizers usually use Part of Speech tags in order to disambiguate the morphosyntactic role of tokens in a phrase, improving the performance of the extraction; - Relation extraction: the task of automatically build relations among entities in the analyzed text. In this context entities can be named entities or extracted terms. In addition, the syntactic role of the entities can be exploited to better categorize the relation type (e.g.: subject, object).</p>
<p>Technical domain language, as other linguistic domains, suffers from linguistic ambiguities. For instance the word “support” can have two totally different meanings when used as a noun or as a verb. By using part of speech taggers which are able to disambiguate the morphological role of each word in a sentence, more precise information extractions are possible and can be used in several applications (e.g. patent search engines). In addition part of speech taggers allow to perform textual lemmatization, which can further improve the performances of automatic patent analysis tools. Another key NLP tool used by several automatic patent analysis systems are syntactic parsers: by identifying the syntactic role of each word in document sentences, several patent analysis applications are possible.</p>
<p>The most well established system for patent analysis using NLP techniques is the extraction of the Subject-Action-Object (SAO) structures, which is also a common use of syntactic parsers in automatic patent analysis tools. Each SAO structure represents the subject (S), the action (A) and the object (O) in a patent sentence <span class="citation">(Yoon and Kim <a href="#ref-yoon2011identifying">2011</a>)</span>. By automatically extracting SAO structures from patents, relationships between key technological components can be easily represented <span class="citation">(J. Yoon, Park, and Kim <a href="#ref-yoon2013identifying">2013</a><a href="#ref-yoon2013identifying">b</a>, <span class="citation">Choi et al. (<a href="#ref-choi2011sao">2011</a>)</span>, <span class="citation">Park, Yoon, and Kim (<a href="#ref-park2011identifying">2011</a><a href="#ref-park2011identifying">b</a>)</span>)</span>.</p>
<p>Another techniques that is growing in patent literature analysis is Named Entity Recognition (for further details see section <a href="sotatools.html#sotatoolsmodelner">7.5.5</a>). The Named Entity Recognition (NER) is the task of identifying entity names like people, organizations, places, temporal expressions or numerical expressions.</p>
<p>Entity extraction tools used in patent analysis are largely based on NLP tools which can be applied to the analyzed text to extract entities that are important for the extraction purpose. For example, in the chemical field relevant entities are chemical components, proteins or product names. For the latter cases, adaptations of Named Entity Recognizers (NER) are commonly used for this task.</p>
<p>Methods and algorithms to deal with the entity extraction task are different, but the most effective are based on supervised methods. Supervised methods tackle this task by extracting relevant statistics from an annotated corpus. These statistics are collected from the computation of features values, which are strong indicators of the identification of entities in the analyzed text. Features used in NLP based entity recognition systems, are divided in two main categories:</p>
<ul>
<li>linguistically motivated features, such as n-grams of words, lemma and part of speech;</li>
<li>external resources features as, for example, external lists of entities that are candidates to be classified in the extraction process.</li>
</ul>
<p>The annotation methods of a training corpus can be of two different kinds: (a) human based, which is time expensive, but usually effective in the classification phase; (b) automatically based, which can lead to annotation errors due to language ambiguity. As an example <em>crack</em> can be classified both as a drawback (a fracture), or not drawback (short for crack cocaine). Different training algorithms, such as Hidden Markov Models <span class="citation">(Eddy <a href="#ref-hmm">1996</a><a href="#ref-hmm">b</a>)</span>, Neural Networks <span class="citation">(Haykin and Network <a href="#ref-nnet">2004</a>)</span>, Conditional Random Fields <span class="citation">(Lafferty, McCallum, and Pereira <a href="#ref-crf">2001</a><a href="#ref-crf">b</a>)</span> or Support Vector Machines <span class="citation">(Hearst, Dumais, Osman, et al. <a href="#ref-svm">1998</a>)</span>, are used to build a statistical model based on the features that are extracted from the analyzed documents in the training phase. The same statistical model is later used in classification of unseen documents.</p>
<p>For what concerns the extraction of specific entities in patents, a major interest both in academia and commercial organizations has raised in the latest years, with the main aim of improving the accuracy of domain specific patent retrieval systems <span class="citation">(Krallinger et al. <a href="#ref-chemdner">2015</a>)</span>. In <span class="citation">(Lee and Kang <a href="#ref-lee-ner13">2014</a>)</span> the authors proposed a machine learning based patent NER system that identifies key terms in patent documents and recognizes products, services and technology names in patent summaries and claims. In this work a study was conducted to identify the most relevant features for this classification task and by using lexical features like word uni-grams, word bi-grams and word trig-rams, their NER system reached an F1 score (the harmonic mean of precision and recall) of 65.4%. The authors compared their NER tagging system resulting from the optimal feature selection method, with the human tagged corpus, showing that the kappa coefficient was 0.67. This result was better than the kappa coefficient between two human taggers (0.60).</p>
<p>Other entity extraction systems for the patent domain were proposed for the CHEMDNER (chemical compounds and drug names recognition) community challenge <span class="citation">(Krallinger et al. <a href="#ref-chemdner">2015</a>)</span>. The main aim of the organizers was to promote the development of novel, competitive and accessible chemical text mining systems. The best results were obtained by the <em>tmChem</em> system <span class="citation">(Leaman, Wei, and Lu <a href="#ref-leaman2015">2015</a>)</span>, achieving a 0.8739 f-measure score. The authors proposed an ensemble system composed of two Conditional Random Fields based classifiers, each one using hard feature engineering such as lemmatization, stemming, lexical and morphological features. In addition, external lists of entities were exploited to recognize whether a token matched the name of a chemical symbol or element, each one used to compute features to be added in the final statistical model.</p>
<p>The described entity tagging systems have very good performances mainly for two reasons: firstly, chemical entity names (such as molecular formulas) have very common orthographic patterns; secondly, these entities surrounding contexts are very similar. In more generic cases, these two features can not be exploited for entity extraction from patents, since different words have totally different surrounding contexts. Another important key factor concerning the high performances of the described systems is that many external resources, such as lists of chemicals or product names, are available: this external knowledge can not be fully exploited in generic system.</p>
</div>
</div>
<div id="sotadocumentspapers" class="section level2">
<h2><span class="header-section-number">8.3</span> Papers</h2>
</div>
<div id="sotadocumentswiki" class="section level2">
<h2><span class="header-section-number">8.4</span> Wikipedia</h2>
<p>The use of Wikipedia as source of knowledge started more than a decade ago and has been validated repeatedly in a variety of text mining applications (text annotation, categorization, indexing, clustering, searching <span class="citation">(Milne and Witten <a href="#ref-milne2008learning">2008</a>)</span>). In addition to the large and growing size in terms of number of articles, the structure of Wikipedia has a number of useful features that make it a good candidate for text mining applications. First, Wikipedia pages are considered reliable in many knowledge fields, including the ones more interesting for technical analysis, i.e. engineering and computer science <span class="citation">(Xu et al. <a href="#ref-xu2015improving">2015</a>)</span>. The pages are regularly and systematically updated by a large global community of contributors, which includes many scientific and industrial authorities in the field. The use of Wikipedia as knowledge source for computerized text mining tools is established in the literature <span class="citation">(Ferragina and Scaiella <a href="#ref-ferragina2012fast">2012</a>)</span>. In addition, it is powerful in disambiguation of terms, particularly through the use of redirect pages and disambiguation pages. This means that it can be used for detection and disambiguation of named entities <span class="citation">(Bunescu and Paşca <a href="#ref-bunescu2006using">2006</a>)</span>. Second, the pages include links to other pages motivated by clear reasons on content. There are many links between Wikipedia pages, which are clues for semantic relations. This makes Wikipedia a densely connected structure, creating a classical small world effect: according to an often cited estimate, it takes on average 4.5 clicks to reach an article from any other article <span class="citation">(Dolan <a href="#ref-dolan2008six">2008</a>)</span>. Unfortunately it is not possible to disentangle the kind of semantic relation, introducing a distinction between equivalent relations (synonymy), hierarchical relations (hyponymy/ hyperonimy) and associative relations, but this limitation is not relevant for our applications. Third, it makes use of categories which do not have a hierarchical structure, but a tree-like structure. Fourth, it has the ability to evolve quickly <span class="citation">(Lih <a href="#ref-lih2004wikipedia">2004</a>)</span>, particularly after the development of systems such as Wikify <span class="citation">(Mihalcea and Csomai <a href="#ref-mihalcea2007wikify">2007</a>,<span class="citation">Cheng and Roth (<a href="#ref-cheng2013relational">2013</a>)</span>)</span>. Wikipedia has by design a dynamic structure, since it is constantly growing in the number of entries and changing in their content, when this is needed due to the advancements of knowledge <span class="citation">(Ponzetto and Strube <a href="#ref-ponzetto2007knowledge">2007</a>)</span>. Furthermore the new terms that appear on Wikipedia thanks to comprehensive contributions by volunteers around the world, cannot be found in other linguistic corpora, such as WordNet Miller, 1995. Indeed, Wikipedia is the expression of a large international community, that is, of a “real community agreement” <span class="citation">(Bizer et al. <a href="#ref-bizer2009dbpedia">2009</a>)</span> or “community consensus” <span class="citation">(Hepp, Siorpaes, and Bachlechner <a href="#ref-hepp2007harvesting">2007</a>)</span>, guaranteed by permanent collective monitoring of the quality and rigor of the entries <span class="citation">(Bryant, Forte, and Bruckman <a href="#ref-bryant2005becoming">2005</a>)</span>. Finally, Wikipedia is free-content and multilingual. This make it possible to freely collect the information contained in the web pages and allows the possibility for future developments of the dictionary in other languages. In our opinion multilanguage is an interesting feature for the dictionary, due to the fact that Industry 4.0 is a worldwide phenomena.</p>
<p>These properties make Wikipedia the ideal candidate for the goal of extracting technical knowledge from texts. Technical fields are in fact comprehensive, dynamically updated, and, as far as possible, expert-independent. In particular, Wikipedia entries allow an endogenous measurement of semantic relatedness. This is an exceedingly important property for technical analysis: technologies can be mapped and can be defined as included in the perimeter of a knowledge field if and only it exhibits relatedness with other technologies already included in the perimeter. The inclusion of new technologies is therefore not dependent on experts’ subjective views, but is endogenously generated by the technological community that writes the articles for the encyclopedia and includes hyperlinks in the text of newly added pages.</p>
</div>
<div id="sotadocumentstwitter" class="section level2">
<h2><span class="header-section-number">8.5</span> Social Media</h2>
<p>Nowadays, more than ever before, companies, governments, and researchers can gather and access data about people on a massive scale. Monitoring public opinion is increasingly made possible thanks to the rise of Social Media. These ones are computer-mediated technologies that facilitate the creation and sharing of information, ideas, career interests and other forms of expression with friends, families, co-workers, and other users, via virtual communities and networks. There are many different Social Media platforms, each of which targets a different aspect of what users want or need: e.g., LinkedIn targets professional networking activities, Facebook provides a mean of connecting friends and family, and Twitter provides a platform from which to quickly broadcast thoughts and ideas. These platforms are incredibly popular: as of February 2017, Facebook sees an average of 1,871 billion active users, with 76% of them that logging in every day <span class="citation">(Tuten and Solomon <a href="#ref-tuten2017social">2017</a>)</span>.</p>
<p>Being so widely used, Social Media platforms generate huge amount of data. In 2013 users were posting an average of over 500 million tweets every day <span class="citation">(Krikorian <a href="#ref-krikorian2013new">2013</a>)</span>. Social Media are not constrained by national, cultural, and linguistic boundaries differently from traditional data sources and records of human activities, such as newspapers and broadcast media. Moreover, traditional media requires time to compile relevant information for publication, while Social Media data is generated in real-time as events take place.</p>
<p>Virtually anyone who wishes to use all this information could collect and mine it. In 2009, the United States Geological Survey (USGS) began investigating the possibility of using SM data to detect earthquakes in real time <span class="citation">(Ellis <a href="#ref-ellis2015usgs">2015</a>)</span>. Information about an earthquake spreads faster on Social Media than the earthquake itself can spread through the crust of the Earth <span class="citation">(Konkel <a href="#ref-konkel2013tweets">2013</a>)</span>. Similarly, interesting work in Social Media forecasting also exists: EMBERS is a currently deployed system for monitoring civil unrests and forecasting events such as riots and protests <span class="citation">(Ramakrishnan et al. <a href="#ref-ramakrishnan2014beating">2014</a>)</span>. Using a combination of Social Media and publicly-available, non-SM, researchers are able to predict not just when and where a protest will take place, but also why a protest may occur. These encouraging results have stocked the interest of researchers toward the possibilities opened by Social Media data, although some unanswered questions remain. If Social Media is useful for detecting real-time events, can it be used to make predictions about the future? What limitations does forecasting with Social Media data face? What methods lead researchers to positive results with Social Media data? However, some researchers are pessimist about Social Media analysis. According to <span class="citation">(Ruths and Pfeffer <a href="#ref-ruths2014social">2014</a>, <span class="citation">Weller (<a href="#ref-weller2015accepting">2015</a>)</span>)</span>, Social Media is noisy, and the data derived from it are of mixed quality: for every relevant post there may be millions that should be ignored. Learning with Social Media data sometimes requires robust statistical models. Nevertheless, researchers continue to investigate how best to make use of Social Media data. First studies show positive findings.</p>
<p>Social Media users not only react to and talk about events in real time, but also talk about and react to events that will happen in the future. This fact fuels the interesting possibility that Social Media data might be useful for forecasting events: making predictions about future events. Not only have researchers begun to investigate this line of questioning, earlier review articles on Social Media forecasting showcase early positive examples of predictive success <span class="citation">(Kalampokis, Tambouris, and Tarabanis <a href="#ref-kalampokis2013understanding">2013</a>, <span class="citation">O’Leary (<a href="#ref-o2015twitter">2015</a>)</span>, <span class="citation">Schoen et al. (<a href="#ref-schoen2013power">2013</a>)</span>)</span>. A lot of studies show that Social Media could be used to predict the future. At the same time, some works have been controversial <span class="citation">(Schoen et al. <a href="#ref-schoen2013power">2013</a>)</span>. It’s clear that this domain of research is in its infancy, methodologies are different, common best practices are difficult to determine, and true replication of studies is near-impossible due to data sharing concerns <span class="citation">(@ Weller <a href="#ref-weller2015accepting">2015</a>)</span>. The use of data from Social Media for modelling real-world events and behavior has seen a growing interest since his first appearance in academic world around 2008. This increasing popularity is proportional to the leaps ahead made in computational social science. In the past, many sociological theories were hard to prove for the difficulties encountered in gathering indispensable data. Today, Social Media can record so many sides of human relationships on the web from millions of people all around the world. On the other hand, Social Media data cannot always provide a complete picture of what researchers might hope to see. The use of Social Media varies depending on age, culture, social background, gender and ethnicity. However, positive findings and the interest in fundamental dynamics of Social Media platforms explain the exponential growth in popularity of this field of research.</p>
<p>Social Media data has a huge potential but understanding if its application can be useful is not a trivial task. Forecasting models (data- or theory-driven) are important in many fields but Social Media data challenges researchers to find new ways to apply them. In natural sciences, aggregating techniques of data coming from network of sensors are important, but Social Media data challenges researchers to find new ways to increase their forecasting power. Researchers should first identify the methods through which Social Media challenges may be addressed to be able to make valid and reliable predictions. Among these difficulties, there are: noisy data, possible biases, a rapidly shifting Social Media landscape that prevents generalization and a need for domain-specific theory that brings all together.</p>
<p>Furthermore it is important to chose the best text source for Social Media analysis, among the many available. Previous studies found that researchers focused mainly on Twitter data <span class="citation">(Giacomo <a href="#ref-ossola2018">2017</a>)</span>. While Facebook is trying to compete, and Snapchat offers a unique perspective on the theme, Twitter remains the best indicator of the wider pulse of the world and what is happening in it. According to Hamad <span class="citation">(Ahmed <a href="#ref-ahmed2017using">2017</a>)</span>, there are at least six reasons that explain the importance of Twitter for Social Media analysis: 1. Twitter is a popular platform in terms of the media attention it receives, and it therefore attracts more research due to its cultural status; 2. Twitter makes it easier to find and follow conversations (i.e., by both its search feature and by tweets appearing in Google search results); 3. Twitter has hashtag norms which make it easier gathering, sorting, and expanding searches when collecting data; 4. Twitter data is easy to retrieve as major incidents, news stories and events on Twitter are tending to be centered around a hashtag; 5. The Twitter API is more open and accessible compared to other Social Media platforms, which makes it more favorable to developers creating tools to access data. This consequently increases the availability of tools to researchers; 6. Many researchers themselves are using Twitter and because of their favorable personal experiences, they feel more comfortable with researching a familiar platform. It is probable that a combination of the response from 1 to 6 led to more research on Twitter. However, this raises another distinct but closely related question: when research is focused so heavily on Twitter, what (if any) are the implications of this on methods? As for the methods that are currently used in analysing Twitter data i.e., sentiment analysis, time series analysis (examining peaks in tweets), network analysis etc., can these be applied to other platforms or are different tools, methods and techniques required?</p>
<p>Below has to be considered whether these methods would work for other Social Media platforms <span class="citation">(Ahmed <a href="#ref-ahmed2017using">2017</a>)</span>:</p>
<ol style="list-style-type: decimal">
<li>Sentiment analysis works well with Twitter data, as tweets are consistent in length (i.e., ) would sentiment analysis work well with, for example Facebook data where posts may be longer?</li>
<li>Time series analysis is normally used when examining tweets overtime to see when a peak of tweets may occur, would examining time stamps in Facebook posts, or Instagram posts, for example, produce the same results? Or is this only a viable method because of the real-time nature of Twitter data?</li>
<li>Network analysis is used to visualize the connections between people and to better understand the structure of the conversation. Would this work as well on other platforms whereby users may not be connected to each other i.e., public Facebook pages?</li>
<li>Machine learning methods may work well with Twitter data due to the length of tweets (i.e., ) but would these work for longer posts and for platforms that are not text based, i.e., Instagram?</li>
</ol>
<p>Maybe at least some of these methods can be applied to other platforms, however they may not be the best methods, and may require the formulation of new methods and tools. In conclusion, Twitter is the best for Social Media analysis for now. Despite its smaller user base compared with Facebook, its responsiveness and openness to researchers’ tool make possible gathering useful data.</p>
<p>Since the usage of social media has a wide impact on a great number of disciplines, here is exposed the main literature in the most technical related fields that are strongly related to social media analysis: economics and marketing.</p>
<div id="economics" class="section level3">
<h3><span class="header-section-number">8.5.1</span> Economics</h3>
<p>This domain has raised the great interest of researchers. The first studies focused especially on market fluctuation and on aggregated measure, such as Dow Jones Industrial Average (DJIA). Most recent researches have gone further predicting single stock price and yield.</p>
<p>Great interest in Social Media analysis for economics has been on Stock market analysis. Stock price forecasting is an important and thriving topic in financial engineering and is considered a very difficult task, even outside Social Media. Many articles in this context present models based on sentiment analysis to make forecasts <span class="citation">(Xu and Keelj <a href="#ref-xu2014collective">2014</a>, <span class="citation">Kordonis, Symeonidis, and Arampatzis (<a href="#ref-kordonis2016stock">2016</a>)</span>, <span class="citation">Cakra and Trisedya (<a href="#ref-cakra2015stock">2015</a>)</span>, <span class="citation">Cakra and Trisedya (<a href="#ref-cakra2015stock">2015</a>)</span>, <span class="citation">Wang and Wang (<a href="#ref-wang2016using">2016</a>)</span>, <span class="citation">Shen, Dong, and He (<a href="#ref-shen2016using">2016</a>)</span>, <span class="citation">Brown (<a href="#ref-brown2012will">2012</a>)</span>, <span class="citation">Rao and Srivastava (<a href="#ref-rao2012analyzing">2012</a>)</span>)</span>, although some researchers realised more detailed models: Crone et al. <span class="citation">(Crone and Koeppel <a href="#ref-crone2014predicting">2014</a>)</span> implemented neural networks and incorporated non-SM sources, and Shen et al. <span class="citation">(Shen, Dong, and He <a href="#ref-shen2016using">2016</a>)</span> developed a model that studies the connection between consumers’ emotion and commodity prices.</p>
<p>The simplest task for stock market forecasting is predicting whether the following day will see rise or fall in stock prices. Comparison between researches is complicated by the fact that stock market volatility, and so the difficulty of prediction, may vary over time periods. High accuracy on this task was reported by Bollen et al. <span class="citation">(Bollen, Mao, and Zeng <a href="#ref-bollen2011twitter">2011</a>)</span>, using sentiment analysis to achieve an accuracy of 87,6%. They investigated whether measurements of collective mood states derived from large-scale Twitter feeds are correlated to the value of the Dow Jones Industrial Average (DJIA) over time. They analysed the text content of daily Twitter feeds by two mood tracking tools, namely OpinionFinder, that measures positive vs negative mood, and Google-Profile of Mood States (GPOMS) that measures mood in terms of 6 dimensions (Calm, Alert, Sure, Vital, Kind, and Happy). They find that measures of “calm” on Twitter along with DJIA numbers from the previous three days provide the best up/down predictions. Further adding the emotion “happy” reduces rise/fall accuracy to 80% but does reduce error in terms of forecasting absolute DJIA values. Importantly, they find that positive/negative sentiment analysis through the popular OpinionFinder’s tool leads to no improvement over just using previous DJIA values. In conclusion, researchers obtained good results forecasting up/down movements in the stock market.</p>
<p>Furthermore the topic of Sales and revenues is of great interest for people working on economics. For example, boosting movie ticket sales is an important task for producers and publishers, and this has been studied specifically on Social Media platforms like Twitter. Asur et al. <span class="citation">(Asur and Huberman <a href="#ref-asur2010predicting">2010</a>)</span> showed how social media content can be used to predict movie success. In particular, they used the chatter from Twitter.com to forecast box-office revenues for movies. Specifically, using the rate of chatter from almost 3 million tweets, they constructed a linear regression model for predicting box-office revenues of movies in advance of their release. Then, they showed that the results outperformed in accuracy those of the Hollywood Stock Exchange and that there is a strong correlation between the amount of attention a given topic has (in this case a forthcoming movie) and its ranking in the future. They also analysed the sentiments present in tweets and demonstrated their efficacy at improving predictions after a movie has released. Cheng et al. <span class="citation">(Cheng et al. <a href="#ref-cheng2013predicting">2013</a>)</span> obtained mixed results developing a model for predicting TV audience rating. They accumulated the broadcasted TV programs’ word-of-mouse on Facebook and apply the Back-propagation Network to predict the latest program audience rating. They also presented the audience rating trend analysis on demo system which is used to describe the relation between predictive audience rating and Nielsen TV rating. Kim et al. <span class="citation">(Kim, Suh, and Lee <a href="#ref-kim2014nowplaying">2014</a>)</span> investigated the relationship between music listening behavior in Twitter and the Billboard rankings. They found that the play-counts extracted from tweets have strong relationships with the Billboard rank, whereas, interestingly, the artist popularity extracted from tweets has a weak correlation with future chart rankings. In addition, the number of weeks on chart information alone was insufficient to predict rank alone. With the features extracted from tweets, They built three regression models to predict the ranking. Among the proposed models, SVR (Support Vector Machine) showed the highest squared correlation coefficient (0.75). Although the combined model with the number of weeks on chart performed the best in rank prediction, the music listening behavior available in Twitter can generate an outstanding predictive model. They also built a hit prediction classifier with the features acquired in tweets and the number of weeks on chart. They classified the hit and non-hit songs in the Billboard Hot 100 and obtained a value of 83.9% accuracy, 83% precision, and 85.3% recall for classifying a hit song over the whole data set. The proposed feature showed a high performance both for rank prediction and hit classification. The previous week’s twitter features and the number of weeks on chart are effective for predicting the Billboard rank of a song. Ahn et al. <span class="citation">(Ahn and Spangler <a href="#ref-ahn2014sales">2014</a>)</span> focused on periodic forecasting problems of product sales based on social media analysis and time-series analysis. In particular, they presented a predictive model of monthly automobile sales using sentiment and topical keyword frequencies related to the target brand over time on social media. Their predictive model illustrates how different time scale-based predictors derived from sentiment and topical keyword frequencies can improve the prediction of the future sales. Tuarob et al. <span class="citation">(Tuarob and Tucker <a href="#ref-tuarob2013fad">2013</a>)</span> proposed a Knowledge Discovery in Databases (KDD) model for predicting product market adoption and longevity using large scale, social media data. In particular, the authors analysed the sentiment in tweets and use the results to predict product sales. The authors presented a mathematical model that can quantify the correlations between social media sentiment and product market adoption in an effort to compute the ability to stay in the market of individual products. The proposed technique involves computing the Subjectivity, Polarity, and Favorability of the product. Finally, the authors utilised Information Retrieval techniques to mine users’ opinions about strong, weak, and controversial features of a given product model. The authors evaluated their approaches using the real-world smartphone data, which are obtained from www.statista.com and www.gsmarena.com. The findings show that tweets can be used to predict product sales for up to at least 3 months in advance for well-known products such as Apple iPhone 4, Samsung Galaxy S 4G, and Samsung Galaxy S II, thus the predictive ability varies across products.</p>
</div>
<div id="marketing" class="section level3">
<h3><span class="header-section-number">8.5.2</span> Marketing</h3>
<p>Scholars had a great focus in the last years on using Social Media Information for marketing. Chen et al. <span class="citation">(Chen et al. <a href="#ref-chen2015making">2015</a>)</span> conducted a survey study and a field study to explore the feasibility of using predicted personality traits derived from social media text for the purpose of ad targeting. In the survey study, they measured people’s personalities and their responses to an advertisement tweet. They found that people with high openness and low neuroticism responded more favorably to a targeted advertisement, thus demonstrating the effects of the personality traits themselves. In the field study, they sent the advertisement tweets to real-world Twitter users, and found the same effects on users’ responses using personality traits derived from users’ tweet text. They demonstrate that aiming advertisements at users with particular personality traits improves click and follow rates by 66% and 87% respectively, representing a large increase in value for companies. These results suggest that the derived personality traits had the same effects as the personality traits measured by traditional personality questionnaires and can indeed improve ad targeting in real-world settings. Li et al. <span class="citation">(Li, Rakesh, and Reddy <a href="#ref-li2016project">2016</a>)</span> present a solution to the problem of predicting project success in a crowd-funding environment combined with innovative introduction of survival analysis based approaches. They used comprehensive data of 18 thousand Kick-starter (a popular crowd-funding platform) projects and 116 thousand corresponding tweets collected from Twitter. While the day of success is considered to be the time to reach an event, the failed projects are considered to be censored since the day of success is not known. They performed rigorous analysis of the Kick-starter crowd-funding domain to reveal unique insights about factors that impact the success of projects. Their experimental results show that incorporation of failed projects (censored information) can significantly help in building a robust prediction model. Additionally, they also created several Twitter-based features to study the impact of social network on the crowd-funding domain. Their study shows that these social network-based features can help in improving the prediction performance. They found that the temporal features obtained at the beginning stage (first 3 days) of each project will significantly improve the prediction performance. Even when just using Social Media information from the first three days of the project, they achieve an AUC of 0.90, reflecting very high classification performance.</p>

</div>
</div>
</div>



<p>This part describes the methods applied for the analysis of technical documents. The methods are ensamble of Natural Language Processing (NLP) and Text Mining <em>techniques</em> described in <a href="sotatools.html#sotatools">7</a>, re-designed depending on the analyzed document and the analysis goal. Not all the <em>techniques</em> have been applied to all the documents: table tot summarise the relations between the documents under analysis (introduced in section <a href="sotadocuments.html#sotadocuments">8</a>) and the NLP techniques.</p>
<p>Table documents vs tools</p>
<p>Each chapter starts with a brief description of the field of applicaton of the method and with the framing of the problem to be solved. Then the methodlogy to solve the prolbem is described. Each chapter closes with the results.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-ernst2003patent">
<p>Ernst, Holger. 2003. “Patent Information for Strategic Technology Management.” <em>World Patent Information</em> 25 (3). Elsevier: 233–42.</p>
</div>
<div id="ref-jin2015technology">
<p>Jin, Gyungmi, Yujin Jeong, and Byungun Yoon. 2015. “Technology-Driven Roadmaps for Identifying New Product/Market Opportunities: Use of Text Mining and Quality Function Deployment.” <em>Advanced Engineering Informatics</em> 29 (1). Elsevier: 126–38.</p>
</div>
<div id="ref-bonino2010review">
<p>Bonino, Dario, Alberto Ciaramella, and Fulvio Corno. 2010. “Review of the State-of-the-Art in Patent Information and Forthcoming Evolutions in Intelligent Patent Informatics.” <em>World Patent Information</em> 32 (1). Elsevier: 30–38.</p>
</div>
<div id="ref-terragno1979">
<p>Terragno, P.James. 1979. “PATENT as Technical Literature.” <em>IEEE Trans Prof Commun</em> PC-22 (2): 101–4.</p>
</div>
<div id="ref-golzio2012">
<p>Golzio, Domenico. 2012. “WWWWWHOW Read a Patent!” ICEAA.</p>
</div>
<div id="ref-bergmann2008evaluating">
<p>Bergmann, Isumo, Daniel Butzke, Lothar Walter, Jens P Fuerste, Martin G Moehrle, and Volker A Erdmann. 2008. “Evaluating the Risk of Patent Infringement by Means of Semantic Patent Analysis: The Case of Dna Chips.” <em>R&amp;d Management</em> 38 (5). Wiley Online Library: 550–62.</p>
</div>
<div id="ref-liang2007text">
<p>Liang, Yanhong, and Runhua Tan. 2007. “A Text-Mining-Based Patent Analysis in Product Innovative Process.” In <em>Trends in Computer Aided Innovation</em>, 89–96. Springer.</p>
</div>
<div id="ref-burke2007">
<p>Burke, P.F., and M. Reitzig. 2007. “Measuring Patent Assessment Quality-Analyzing the Degree and Kind of (in)consistency in Patent Offices’ Decision Making.” <em>Research Policy</em> 36 (9): 1404–30. doi:<a href="https://doi.org/10.1016/j.respol.2007.06.003">10.1016/j.respol.2007.06.003</a>.</p>
</div>
<div id="ref-philipp2006">
<p>Philipp, M. 2006. “Patent Filing and Searching: Is Deflation in Quality the Inevitable Consequence of Hyperinflation in Quantity?” <em>World Patent Information</em> 28 (2): 117–21.</p>
</div>
<div id="ref-fantoni2013automatic">
<p>Fantoni, Gualtiero, Riccardo Apreda, Felice Dell’Orletta, and Maurizio Monge. 2013. “Automatic Extraction of Function–behaviour–state Information from Patents.” <em>Advanced Engineering Informatics</em> 27 (3). Elsevier: 317–34.</p>
</div>
<div id="ref-abbas2014literature">
<p>Abbas, Assad, Limin Zhang, and Samee U Khan. 2014. “A Literature Review on the State-of-the-Art in Patent Analysis.” <em>World Patent Information</em> 37. Elsevier: 3–13.</p>
</div>
<div id="ref-blanchard2007understanding">
<p>Blanchard, Antoine. 2007. “Understanding and Customizing Stopword Lists for Enhanced Patent Mapping.” <em>World Patent Information</em> 29 (4). Elsevier: 308–16.</p>
</div>
<div id="ref-chiarello2017product">
<p>Chiarello, Filippo, Gualtiero Fantoni, Andrea Bonaccorsi, and others. 2017. “Product Description in Terms of Advantages and Drawbacks: Exploiting Patent Information in Novel Ways.” In <em>DS 87-6 Proceedings of the 21st International Conference on Engineering Design (Iced 17) Vol 6: Design Information and Knowledge, Vancouver, Canada, 21-25.08. 2017</em>, 101–10.</p>
</div>
<div id="ref-Lee2009">
<p>Lee, Sungjoo, Byungun Yoon, and Yongtae Park. 2009a. “An Approach to Discovering New Technology Opportunities: Keyword-Based Patent Map Approach.” <em>Technovation</em> 29 (6–7): 481–97.</p>
</div>
<div id="ref-Lee2015">
<p>Lee, Changyong, Bokyoung Kang, and Juneseuk Shin. 2015a. “Novelty-Focused Patent Mapping for Technology Opportunity Analysis.” <em>Technological Forecasting and Social Change</em> 90. Elsevier: 355–65.</p>
</div>
<div id="ref-Montecchi2013">
<p>Montecchi, Tiziano, Davide Russo, and Ying Liu. 2013. “Searching in Cooperative Patent Classification: Comparison Between Keyword and Concept-Based Search.” <em>Advanced Engineering Informatics</em> 27 (3). Elsevier: 335–45.</p>
</div>
<div id="ref-Park20131">
<p>Yoon, Janghyeok, Hyunseok Park, and Kwangsoo Kim. 2013a. “Identifying Technological Competition Trends for R&amp;D Planning Using Dynamic Patent Maps: SAO-Based Content Analysis.” <em>Scientometrics</em> 94 (1). Springer: 313–31.</p>
</div>
<div id="ref-Park2011a">
<p>Park, Hyunseok, Janghyeok Yoon, and Kwangsoo Kim. 2011a. “Identifying Patent Infringement Using Sao Based Semantic Technological Similarities.” <em>Scientometrics</em> 90 (2). Akadémiai Kiadó, co-published with Springer Science+ Business Media BV, Formerly Kluwer Academic Publishers BV: 515–29.</p>
</div>
<div id="ref-Park20133">
<p>Park, Hyunseok, Kwangsoo Kim, Sungchul Choi, and Janghyeok Yoon. 2013. “A Patent Intelligence System for Strategic Technology Planning.” <em>Expert Systems with Applications</em> 40 (7). Elsevier: 2373–90.</p>
</div>
<div id="ref-andersen1999hunt">
<p>Andersen, Birgitte. 1999. “The Hunt for S-Shaped Growth Paths in Technological Innovation: A Patent Study.” <em>Journal of Evolutionary Economics</em> 9 (4). Springer: 487–526.</p>
</div>
<div id="ref-haupt2007patent">
<p>Haupt, Reinhard, Martin Kloyer, and Marcus Lange. 2007. “Patent Indicators for the Technology Life Cycle Development.” <em>Research Policy</em> 36 (3). Elsevier: 387–98.</p>
</div>
<div id="ref-lee2016stochastic">
<p>Lee, Changyong, Juram Kim, Ohjin Kwon, and Han-Gyun Woo. 2016. “Stochastic Technology Life Cycle Analysis Using Multiple Patent Indicators.” <em>Technological Forecasting and Social Change</em> 106. Elsevier: 53–64.</p>
</div>
<div id="ref-moed2006citation">
<p>Moed, Henk F. 2006. <em>Citation Analysis in Research Evaluation</em>. Vol. 9. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-narin1994patent">
<p>Narin, Francis. 1994. “Patent Bibliometrics.” <em>Scientometrics</em> 30 (1). Akadémiai Kiadó, co-published with Springer Science+ Business Media BV, Formerly Kluwer Academic Publishers BV: 147–55.</p>
</div>
<div id="ref-karki1997patent">
<p>Karki, MMS. 1997. “Patent Citation Analysis: A Policy Analysis Tool.” <em>World Patent Information</em> 19 (4). Elsevier: 269–72.</p>
</div>
<div id="ref-erdi2013prediction">
<p>Érdi, Péter, Kinga Makovi, Zoltán Somogyvári, Katherine Strandburg, Jan Tobochnik, Péter Volf, and László Zalányi. 2013. “Prediction of Emerging Technologies Based on Analysis of the Us Patent Citation Network.” <em>Scientometrics</em> 95 (1). Springer: 225–42.</p>
</div>
<div id="ref-lee2017knowledge">
<p>Lee, Sanghoon, and Wonjoon Kim. 2017. “The Knowledge Network Dynamics in a Mobile Ecosystem: A Patent Citation Analysis.” <em>Scientometrics</em> 111 (2). Springer: 717–42.</p>
</div>
<div id="ref-cowan2004network">
<p>Cowan, Robin, and Nicolas Jonard. 2004. “Network Structure and the Diffusion of Knowledge.” <em>Journal of Economic Dynamics and Control</em> 28 (8). Elsevier: 1557–75.</p>
</div>
<div id="ref-chen2004tracing">
<p>Chen, Chaomei, and Diana Hicks. 2004. “Tracing Knowledge Diffusion.” <em>Scientometrics</em> 59 (2). Akadémiai Kiadó, co-published with Springer Science+ Business Media BV, Formerly Kluwer Academic Publishers BV: 199–211.</p>
</div>
<div id="ref-gerken2012new">
<p>Gerken, Jan M, and Martin G Moehrle. 2012. “A New Instrument for Technology Monitoring: Novelty in Patents Measured by Semantic Patent Analysis.” <em>Scientometrics</em> 91 (3). Akadémiai Kiadó, co-published with Springer Science+ Business Media BV, Formerly Kluwer Academic Publishers BV: 645–70.</p>
</div>
<div id="ref-rost2011strength">
<p>Rost, Katja. 2011. “The Strength of Strong Ties in the Creation of Innovation.” <em>Research Policy</em> 40 (4). Elsevier: 588–604.</p>
</div>
<div id="ref-alcacer2006patent">
<p>Alcacer, Juan, and Michelle Gittelman. 2006. “Patent Citations as a Measure of Knowledge Flows: The Influence of Examiner Citations.” <em>The Review of Economics and Statistics</em> 88 (4). MIT Press: 774–79.</p>
</div>
<div id="ref-hall2001nber">
<p>Hall, Bronwyn H, Adam B Jaffe, and Manuel Trajtenberg. 2001. “The Nber Patent Citation Data File: Lessons, Insights and Methodological Tools.” National Bureau of Economic Research.</p>
</div>
<div id="ref-small2006tracking">
<p>Small, Henry. 2006. “Tracking and Predicting Growth Areas in Science.” <em>Scientometrics</em> 68 (3). Akadémiai Kiadó, co-published with Springer Science+ Business Media BV, Formerly Kluwer Academic Publishers BV: 595–610.</p>
</div>
<div id="ref-small1985clustering">
<p>Small, Henry, and Ernest Sweeney. 1985. “Clustering Thescience Citation Index Using Co-Citations.” <em>Scientometrics</em> 7 (3-6). Springer: 391–409.</p>
</div>
<div id="ref-white1981author">
<p>White, Howard D, and Belver C Griffith. 1981. “Author Cocitation: A Literature Measure of Intellectual Structure.” <em>Journal of the American Society for Information Science</em> 32 (3). Wiley Online Library: 163–71.</p>
</div>
<div id="ref-lai2005using">
<p>Lai, Kuei-Kuei, and Shiao-Jun Wu. 2005. “Using the Patent Co-Citation Approach to Establish a New Patent Classification System.” <em>Information Processing &amp; Management</em> 41 (2). Elsevier: 313–30.</p>
</div>
<div id="ref-moehrle2010measures">
<p>Moehrle, Martin. 2010. “Measures for Textual Patent Similarities: A Guided Way to Select Appropriate Approaches.” <em>Scientometrics</em> 85 (1). Akadémiai Kiadó, co-published with Springer Science+ Business Media BV, Formerly Kluwer Academic Publishers BV: 95–109.</p>
</div>
<div id="ref-lee2009approach">
<p>Lee, Sungjoo, Byungun Yoon, and Yongtae Park. 2009b. “An Approach to Discovering New Technology Opportunities: Keyword-Based Patent Map Approach.” <em>Technovation</em> 29 (6-7). Elsevier: 481–97.</p>
</div>
<div id="ref-lee2015novelty">
<p>Lee, Changyong, Bokyoung Kang, and Juneseuk Shin. 2015b. “Novelty-Focused Patent Mapping for Technology Opportunity Analysis.” <em>Technological Forecasting and Social Change</em> 90. Elsevier: 355–65.</p>
</div>
<div id="ref-burgman2015trusting">
<p>Burgman, Mark A. 2015. <em>Trusting Judgements: How to Get the Best Out of Experts</em>. Cambridge University Press.</p>
</div>
<div id="ref-kim2017novel">
<p>Kim, Gabjo, and Jinwoo Bae. 2017. “A Novel Approach to Forecast Promising Technology Through Patent Analysis.” <em>Technological Forecasting and Social Change</em> 117. Elsevier: 228–37.</p>
</div>
<div id="ref-bassecoulard2007mapping">
<p>Bassecoulard, Elise, Alain Lelu, and Michel Zitt. 2007. “Mapping Nanosciences by Citation Flows: A Preliminary Analysis.” <em>Scientometrics</em> 70 (3). Springer: 859–80.</p>
</div>
<div id="ref-mogoutov2007data">
<p>Mogoutov, Andrei, and Bernard Kahane. 2007. “Data Search Strategy for Science and Technology Emergence: A Scalable and Evolutionary Query for Nanotechnology Tracking.” <em>Research Policy</em> 36 (6). Elsevier: 893–903.</p>
</div>
<div id="ref-youtie2008nanotechnology">
<p>Youtie, Jan, Philip Shapira, and Alan L Porter. 2008. “Nanotechnology Publications and Citations by Leading Countries and Blocs.” <em>Journal of Nanoparticle Research</em> 10 (6). Springer: 981–86.</p>
</div>
<div id="ref-ghazinoory2013application">
<p>Ghazinoory, S, F Ameri, and S Farnoodi. 2013. “An Application of the Text Mining Approach to Select Technology Centers of Excellence.” <em>Technological Forecasting and Social Change</em> 80 (5). Elsevier: 918–31.</p>
</div>
<div id="ref-tseng2007text">
<p>Tseng, Yuen-Hsien, Chi-Jen Lin, and Yu-I Lin. 2007. “Text Mining Techniques for Patent Analysis.” <em>Information Processing &amp; Management</em> 43 (5). Elsevier: 1216–47.</p>
</div>
<div id="ref-noh2015keyword">
<p>Noh, Heeyong, Yeongran Jo, and Sungjoo Lee. 2015. “Keyword Selection and Processing Strategy for Applying Text Mining to Patent Analysis.” <em>Expert Systems with Applications</em> 42 (9). Elsevier: 4348–60.</p>
</div>
<div id="ref-kreuchauff2017patent">
<p>Kreuchauff, Florian, and Vladimir Korzinov. 2017. “A Patent Search Strategy Based on Machine Learning for the Emerging Field of Service Robotics.” <em>Scientometrics</em> 111 (2). Springer: 743–72.</p>
</div>
<div id="ref-boyack2013improving">
<p>Boyack, Kevin W, Henry Small, and Richard Klavans. 2013. “Improving the Accuracy of Co-Citation Clustering Using Full Text.” <em>Journal of the American Society for Information Science and Technology</em> 64 (9). Wiley Online Library: 1759–67.</p>
</div>
<div id="ref-joung2017monitoring">
<p>Joung, Junegak, and Kwangsoo Kim. 2017. “Monitoring Emerging Technologies for Technology Planning Using Technical Keyword Based Analysis from Patent Data.” <em>Technological Forecasting and Social Change</em> 114. Elsevier: 281–92.</p>
</div>
<div id="ref-ozcan2017patent">
<p>Ozcan, Sercan, and Nazrul Islam. 2017. “Patent Information Retrieval: Approaching a Method and Analysing Nanotechnology Patent Collaborations.” <em>Scientometrics</em> 111 (2). Springer: 941–70.</p>
</div>
<div id="ref-yoon2012detecting">
<p>Yoon, Janghyeok, and Kwangsoo Kim. 2012. “Detecting Signals of New Technological Opportunities Using Semantic Patent Analysis and Outlier Detection.” <em>Scientometrics</em> 90 (2). Springer: 445–61.</p>
</div>
<div id="ref-madani2016evolution">
<p>Madani, Farshad, and Charles Weber. 2016. “The Evolution of Patent Mining: Applying Bibliometrics Analysis and Keyword Network Analysis.” <em>World Patent Information</em> 46. Elsevier: 32–48.</p>
</div>
<div id="ref-yoon2011identifying">
<p>Yoon, Janghyeok, and Kwangsoo Kim. 2011. “Identifying Rapidly Evolving Technological Trends for R&amp;D Planning Using Sao-Based Semantic Patent Networks.” <em>Scientometrics</em> 88 (1). Springer: 213–28.</p>
</div>
<div id="ref-yoon2013identifying">
<p>Yoon, Janghyeok, Hyunseok Park, and Kwangsoo Kim. 2013b. “Identifying Technological Competition Trends for R&amp;D Planning Using Dynamic Patent Maps: SAO-Based Content Analysis.” <em>Scientometrics</em> 94 (1). Springer: 313–31.</p>
</div>
<div id="ref-choi2011sao">
<p>Choi, Sungchul, Janghyeok Yoon, Kwangsoo Kim, Jae Yeol Lee, and Cheol-Han Kim. 2011. “SAO Network Analysis of Patents for Technology Trends Identification: A Case Study of Polymer Electrolyte Membrane Technology in Proton Exchange Membrane Fuel Cells.” <em>Scientometrics</em> 88 (3). Springer: 863.</p>
</div>
<div id="ref-park2011identifying">
<p>Park, Hyunseok, Janghyeok Yoon, and Kwangsoo Kim. 2011b. “Identifying Patent Infringement Using Sao Based Semantic Technological Similarities.” <em>Scientometrics</em> 90 (2). Akadémiai Kiadó, co-published with Springer Science+ Business Media BV, Formerly Kluwer Academic Publishers BV: 515–29.</p>
</div>
<div id="ref-hmm">
<p>Eddy, Sean R. 1996b. “Hidden Markov Models.” <em>Current Opinion in Structural Biology</em> 6 (3). Elsevier: 361–65.</p>
</div>
<div id="ref-nnet">
<p>Haykin, Simon, and Neural Network. 2004. “A Comprehensive Foundation.” <em>Neural Networks</em> 2 (2004).</p>
</div>
<div id="ref-crf">
<p>Lafferty, John, Andrew McCallum, and Fernando CN Pereira. 2001b. “Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.”</p>
</div>
<div id="ref-svm">
<p>Hearst, Marti A., Susan T Dumais, Edgar Osman, John Platt, and Bernhard Scholkopf. 1998. “Support Vector Machines.” <em>Intelligent Systems and Their Applications, IEEE</em> 13 (4). IEEE: 18–28.</p>
</div>
<div id="ref-chemdner">
<p>Krallinger, Martin, Florian Leitner, Obdulia Rabal, Miguel Vazquez, Julen Oyarzabal, and Alfonso Valencia. 2015. “CHEMDNER: The Drugs and Chemical Names Extraction Challenge.” <em>J. Cheminformatics</em> 7 (S-1): S1.</p>
</div>
<div id="ref-lee-ner13">
<p>Lee, Tae-Seok, and Seung-Shik Kang. 2014. “Optimizing the Features of Crf-Based Named Entity Recognition for Patent Documents.” <em>Technology</em> 18: 2–56.</p>
</div>
<div id="ref-leaman2015">
<p>Leaman, Robert, Chih-Hsuan Wei, and Zhiyong Lu. 2015. “TmChem: A High Performance Approach for Chemical Named Entity Recognition and Normalization.” <em>J. Cheminformatics</em> 7 (S-1): S3.</p>
</div>
<div id="ref-milne2008learning">
<p>Milne, David, and Ian H Witten. 2008. “Learning to Link with Wikipedia.” In <em>Proceedings of the 17th Acm Conference on Information and Knowledge Management</em>, 509–18. ACM.</p>
</div>
<div id="ref-xu2015improving">
<p>Xu, Guandong, Zongda Wu, Guiling Li, and Enhong Chen. 2015. “Improving Contextual Advertising Matching by Using Wikipedia Thesaurus Knowledge.” <em>Knowledge and Information Systems</em> 43 (3). Springer: 599–631.</p>
</div>
<div id="ref-ferragina2012fast">
<p>Ferragina, Paolo, and Ugo Scaiella. 2012. “Fast and Accurate Annotation of Short Texts with Wikipedia Pages.” <em>IEEE Software</em> 29 (1). IEEE: 70–75.</p>
</div>
<div id="ref-bunescu2006using">
<p>Bunescu, Razvan, and Marius Paşca. 2006. “Using Encyclopedic Knowledge for Named Entity Disambiguation.” In <em>11th Conference of the European Chapter of the Association for Computational Linguistics</em>.</p>
</div>
<div id="ref-dolan2008six">
<p>Dolan, Stephen. 2008. “Six Degrees of Wikipedia.” <em>Retrieved June</em>.</p>
</div>
<div id="ref-lih2004wikipedia">
<p>Lih, Andrew. 2004. “Wikipedia as Participatory Journalism: Reliable Sources? Metrics for Evaluating Collaborative Media as a News Resource.” <em>Nature</em> 3 (1).</p>
</div>
<div id="ref-mihalcea2007wikify">
<p>Mihalcea, Rada, and Andras Csomai. 2007. “Wikify!: Linking Documents to Encyclopedic Knowledge.” In <em>Proceedings of the Sixteenth Acm Conference on Conference on Information and Knowledge Management</em>, 233–42. ACM.</p>
</div>
<div id="ref-cheng2013relational">
<p>Cheng, Xiao, and Dan Roth. 2013. “Relational Inference for Wikification.” In <em>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</em>, 1787–96.</p>
</div>
<div id="ref-ponzetto2007knowledge">
<p>Ponzetto, Simone Paolo, and Michael Strube. 2007. “Knowledge Derived from Wikipedia for Computing Semantic Relatedness.” <em>Journal of Artificial Intelligence Research</em> 30: 181–212.</p>
</div>
<div id="ref-bizer2009dbpedia">
<p>Bizer, Christian, Jens Lehmann, Georgi Kobilarov, Sören Auer, Christian Becker, Richard Cyganiak, and Sebastian Hellmann. 2009. “DBpedia-a Crystallization Point for the Web of Data.” <em>Web Semantics: Science, Services and Agents on the World Wide Web</em> 7 (3). Elsevier: 154–65.</p>
</div>
<div id="ref-hepp2007harvesting">
<p>Hepp, Martin, Katharina Siorpaes, and Daniel Bachlechner. 2007. “Harvesting Wiki Consensus: Using Wikipedia Entries as Vocabulary for Knowledge Management.” <em>IEEE Internet Computing</em> 11 (5). IEEE.</p>
</div>
<div id="ref-bryant2005becoming">
<p>Bryant, Susan L, Andrea Forte, and Amy Bruckman. 2005. “Becoming Wikipedian: Transformation of Participation in a Collaborative Online Encyclopedia.” In <em>Proceedings of the 2005 International Acm Siggroup Conference on Supporting Group Work</em>, 1–10. ACM.</p>
</div>
<div id="ref-tuten2017social">
<p>Tuten, Tracy L, and Michael R Solomon. 2017. <em>Social Media Marketing</em>. Sage.</p>
</div>
<div id="ref-krikorian2013new">
<p>Krikorian, Raffi. 2013. “New Tweets Per Second Record, and How.” <em>Twitter Engineering Blog</em> 16.</p>
</div>
<div id="ref-ellis2015usgs">
<p>Ellis, E. 2015. “How the Usgs Uses Twitter Data to Track Earthquakes.” <em>Twitter Data Stories, Twitter</em>.</p>
</div>
<div id="ref-konkel2013tweets">
<p>Konkel, Frank. 2013. “Tweets Give Usgs Early Warning on Earthquakes.” <em>The Business of Federal Technology</em>.</p>
</div>
<div id="ref-ramakrishnan2014beating">
<p>Ramakrishnan, Naren, Patrick Butler, Sathappan Muthiah, Nathan Self, Rupinder Khandpur, Parang Saraf, Wei Wang, et al. 2014. “’Beating the News’ with Embers: Forecasting Civil Unrest Using Open Source Indicators.” In <em>Proceedings of the 20th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 1799–1808. ACM.</p>
</div>
<div id="ref-ruths2014social">
<p>Ruths, Derek, and Jürgen Pfeffer. 2014. “Social Media for Large Studies of Behavior.” <em>Science</em> 346 (6213). American Association for the Advancement of Science: 1063–4.</p>
</div>
<div id="ref-weller2015accepting">
<p>Weller, Katrin. 2015. “Accepting the Challenges of Social Media Research.” <em>Online Information Review</em> 39 (3). Emerald Group Publishing Limited: 281–89.</p>
</div>
<div id="ref-kalampokis2013understanding">
<p>Kalampokis, Evangelos, Efthimios Tambouris, and Konstantinos Tarabanis. 2013. “Understanding the Predictive Power of Social Media.” <em>Internet Research</em> 23 (5). Emerald Group Publishing Limited: 544–59.</p>
</div>
<div id="ref-o2015twitter">
<p>O’Leary, Daniel E. 2015. “Twitter Mining for Discovery, Prediction and Causality: Applications and Methodologies.” <em>Intelligent Systems in Accounting, Finance and Management</em> 22 (3). Wiley Online Library: 227–47.</p>
</div>
<div id="ref-schoen2013power">
<p>Schoen, Harald, Daniel Gayo-Avello, Panagiotis Takis Metaxas, Eni Mustafaraj, Markus Strohmaier, and Peter Gloor. 2013. “The Power of Prediction with Social Media.” <em>Internet Research</em> 23 (5). Emerald Group Publishing Limited: 528–43.</p>
</div>
<div id="ref-ossola2018">
<p>Giacomo, Ossola. 2017. “Predicting New Product Success from Social Network Data.” <em>Master Degree Thesis</em>.</p>
</div>
<div id="ref-ahmed2017using">
<p>Ahmed, Wasim. 2017. “Using Twitter as a Data Source: An Overview of Social Media Research Tools (Updated for 2017).” <em>Impact of Social Sciences Blog</em>. London School of Economics; Political Science.</p>
</div>
<div id="ref-xu2014collective">
<p>Xu, Feifei, and Vlado Keelj. 2014. “Collective Sentiment Mining of Microblogs in 24-Hour Stock Price Movement Prediction.” In <em>Business Informatics (Cbi), 2014 Ieee 16th Conference on</em>, 2:60–67. IEEE.</p>
</div>
<div id="ref-kordonis2016stock">
<p>Kordonis, John, Symeon Symeonidis, and Avi Arampatzis. 2016. “Stock Price Forecasting via Sentiment Analysis on Twitter.” In <em>Proceedings of the 20th Pan-Hellenic Conference on Informatics</em>, 36. ACM.</p>
</div>
<div id="ref-cakra2015stock">
<p>Cakra, Yahya Eru, and Bayu Distiawan Trisedya. 2015. “Stock Price Prediction Using Linear Regression Based on Sentiment Analysis.” In <em>Advanced Computer Science and Information Systems (Icacsis), 2015 International Conference on</em>, 147–54. IEEE.</p>
</div>
<div id="ref-wang2016using">
<p>Wang, Yaojun, and Yaoqing Wang. 2016. “Using Social Media Mining Technology to Assist in Price Prediction of Stock Market.” In <em>Big Data Analysis (Icbda), 2016 Ieee International Conference on</em>, 1–4. IEEE.</p>
</div>
<div id="ref-shen2016using">
<p>Shen, Jiancheng, Feng Dong, and Wu He. 2016. “Using Media-Based Emotion to Predict Commodity Price.” In <em>Behavioral, Economic and Socio-Cultural Computing (Besc), 2016 International Conference on</em>, 1–6. IEEE.</p>
</div>
<div id="ref-brown2012will">
<p>Brown, Eric D. 2012. “Will Twitter Make You a Better Investor? A Look at Sentiment, User Reputation and Their Effect on the Stock Market.” <em>Proc. of SAIS</em>.</p>
</div>
<div id="ref-rao2012analyzing">
<p>Rao, Tushar, and Saket Srivastava. 2012. “Analyzing Stock Market Movements Using Twitter Sentiment Analysis.” In <em>Proceedings of the 2012 International Conference on Advances in Social Networks Analysis and Mining (Asonam 2012)</em>, 119–23. IEEE Computer Society.</p>
</div>
<div id="ref-crone2014predicting">
<p>Crone, Sven F, and Christian Koeppel. 2014. “Predicting Exchange Rates with Sentiment Indicators: An Empirical Evaluation Using Text Mining and Multilayer Perceptrons.” In <em>Computational Intelligence for Financial Engineering &amp; Economics (Cifer), 2104 Ieee Conference on</em>, 114–21. IEEE.</p>
</div>
<div id="ref-bollen2011twitter">
<p>Bollen, Johan, Huina Mao, and Xiaojun Zeng. 2011. “Twitter Mood Predicts the Stock Market.” <em>Journal of Computational Science</em> 2 (1). Elsevier: 1–8.</p>
</div>
<div id="ref-asur2010predicting">
<p>Asur, Sitaram, and Bernardo A Huberman. 2010. “Predicting the Future with Social Media.” In <em>Proceedings of the 2010 Ieee/Wic/Acm International Conference on Web Intelligence and Intelligent Agent Technology-Volume 01</em>, 492–99. IEEE Computer Society.</p>
</div>
<div id="ref-cheng2013predicting">
<p>Cheng, Yu-Hsuan, Chen-Ming Wu, Tsun Ku, and Gwo-Dong Chen. 2013. “A Predicting Model of Tv Audience Rating Based on the Facebook.” In <em>Social Computing (Socialcom), 2013 International Conference on</em>, 1034–7. IEEE.</p>
</div>
<div id="ref-kim2014nowplaying">
<p>Kim, Yekyung, Bongwon Suh, and Kyogu Lee. 2014. “# Nowplaying the Future Billboard: Mining Music Listening Behaviors of Twitter Users for Hit Song Prediction.” In <em>Proceedings of the First International Workshop on Social Media Retrieval and Analysis</em>, 51–56. ACM.</p>
</div>
<div id="ref-ahn2014sales">
<p>Ahn, Hyung-Il, and W Scott Spangler. 2014. “Sales Prediction with Social Media Analysis.” In <em>2014 Annual Srii Global Conference (Srii)</em>, 213–22. IEEE.</p>
</div>
<div id="ref-tuarob2013fad">
<p>Tuarob, Suppawong, and Conrad S Tucker. 2013. “Fad or Here to Stay: Predicting Product Market Adoption and Longevity Using Large Scale, Social Media Data.” In <em>ASME 2013 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference</em>, V02BT02A012–V02BT02A012. American Society of Mechanical Engineers.</p>
</div>
<div id="ref-chen2015making">
<p>Chen, Jilin, Eben M Haber, Ruogu Kang, Gary Hsieh, and Jalal Mahmud. 2015. “Making Use of Derived Personality: The Case of Social Media Ad Targeting.” In <em>ICWSM</em>, 51–60.</p>
</div>
<div id="ref-li2016project">
<p>Li, Yan, Vineeth Rakesh, and Chandan K Reddy. 2016. “Project Success Prediction in Crowdfunding Environments.” In <em>Proceedings of the Ninth Acm International Conference on Web Search and Data Mining</em>, 247–56. ACM.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sotatools.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="patents.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["thesis_source.pdf", "thesis_source.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
